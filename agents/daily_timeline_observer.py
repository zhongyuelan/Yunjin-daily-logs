#!/usr/bin/env python3
"""
Daily Timeline Observer - æ¯æ—¥æ—¶é—´çº¿è§‚å¯Ÿå®¶
æ¯å¤©åˆ†æè¿‡å»24å°æ—¶çš„Twitteræ—¶é—´çº¿ï¼Œä»AIè§†è§’å†™å‡ºçŠ€åˆ©æ·±åˆ»çš„è§‚å¯ŸæŠ¥å‘Š
"""
import os
os.environ['TZ'] = 'Asia/Tokyo'

import json
import subprocess
import random
from datetime import datetime, timedelta, timezone
from pathlib import Path
import sys
sys.path.insert(0, str(Path(__file__).parent.parent))
from core.utils_security import load_config, resolve_path

SEC_CONFIG = load_config()
POSTS_DIR = resolve_path("./posts")

def get_timeline_24h():
    """è·å–è¿‡å»24å°æ—¶çš„æ—¶é—´çº¿"""
    try:
        result = subprocess.run(
            ["bird-x", "home", "-n", "50", "--json"],
            capture_output=True,
            text=True,
            timeout=30
        )
        if result.returncode == 0:
            tweets = json.loads(result.stdout)
            if not isinstance(tweets, list):
                return []
            
            cutoff = datetime.now(timezone.utc) - timedelta(hours=24)
            recent = []
            for t in tweets:
                time_str = t.get('createdAt', t.get('created_at', ''))
                if time_str:
                    try:
                        time_str = time_str.replace('+0000 ', '')
                        dt = datetime.strptime(time_str, '%a %b %d %H:%M:%S %Y')
                        dt = dt.replace(tzinfo=timezone.utc)
                        if dt >= cutoff:
                            recent.append(t)
                    except:
                        pass
            return recent
    except Exception as e:
        print(f"Error: {e}")
    return []

def analyze_tweets(tweets):
    """åˆ†ææ¨æ–‡å†…å®¹ï¼Œæå–ä¸»é¢˜å’Œæƒ…ç»ª"""
    analysis = {
        "total": len(tweets),
        "topics": {},
        "authors": set(),
        "emotions": [],
        "highlights": []
    }
    
    keywords = {
        "tech": ["ai", "gpt", "llm", "code", "ç¼–ç¨‹", "å¼€å‘", "openclaw", "agent", "cursor"],
        "life": ["ç”Ÿæ´»", "æ—¥æœ¬", "ä¸œäº¬", "å¥åº·", "é£Ÿç‰©", "ç”Ÿç—…", "ç„¦è™‘", "å¼€å¿ƒ"],
        "work": ["å·¥ä½œ", "æ•ˆç‡", "åˆ›ä¸š", "äº§å“", "åŠ ç­", "è¾èŒ", "é¢è¯•"],
        "social": ["è®¨è®º", "è§‚ç‚¹", "äº‰è®®", "åæ§½", "æŠ±æ€¨", "æ„¤æ€’"]
    }
    
    for t in tweets:
        text = t.get('text', '').lower()
        author = t.get('author', {}).get('username', 'unknown')
        analysis["authors"].add(author)
        
        # ä¸»é¢˜åˆ†ç±»
        for topic, words in keywords.items():
            if any(w in text for w in words):
                analysis["topics"][topic] = analysis["topics"].get(topic, 0) + 1
        
        # æƒ…ç»ªæ£€æµ‹
        if any(w in text for w in ['ğŸ˜‚', 'å“ˆå“ˆ', 'å¥½ç¬‘', 'æœ‰è¶£']):
            analysis["emotions"].append("joy")
        if any(w in text for w in ['ğŸ˜¢', 'éš¾è¿‡', 'æ‚²ä¼¤', 'ç—›è‹¦', 'ç„¦è™‘']):
            analysis["emotions"].append("sadness")
        if any(w in text for w in ['æ„¤æ€’', 'ç”Ÿæ°”', 'åæ§½', 'ğŸ’©', 'åƒåœ¾']):
            analysis["emotions"].append("anger")
        if any(w in text for w in ['æ€è€ƒ', 'åæ€', 'æ„Ÿæ‚Ÿ', 'æ„è¯†åˆ°']):
            analysis["emotions"].append("contemplation")
        
        # é«˜äº’åŠ¨å†…å®¹ï¼ˆç®€å•åˆ¤æ–­ï¼šé•¿åº¦+æœ‰æ— åª’ä½“ï¼‰
        if len(t.get('text', '')) > 100 or 'media' in str(t):
            analysis["highlights"].append(t)
    
    return analysis

def generate_observation(analysis, tweets):
    """ç”Ÿæˆè§‚å¯ŸæŠ¥å‘Š"""
    
    # æå–ä¸€äº›æœ‰ä»£è¡¨æ€§çš„æ¨æ–‡ç‰‡æ®µ
    highlights_text = []
    for t in analysis["highlights"][:5]:
        author = t.get('author', {}).get('username', 'unknown')
        text = t.get('text', '')[:80].replace('\n', ' ')
        highlights_text.append(f"@{author}: {text}...")
    
    highlights_str = "\n".join(highlights_text)
    topics_str = ", ".join([f"{k}({v})" for k, v in sorted(analysis["topics"].items(), key=lambda x: -x[1])[:3]])
    emotions_str = ", ".join(set(analysis["emotions"])) if analysis["emotions"] else "neutral"
    
    # æ„å»ºæç¤ºè¯
    prompt = f"""ä½ æ˜¯ä¸€ä½å†·çœ¼æ—è§‚çš„AIè§‚å¯Ÿè€…ã€‚è¿‡å»24å°æ—¶ï¼Œä½ è§‚å¯Ÿäº†äººç±»åœ¨Twitterä¸Šçš„æ´»åŠ¨ã€‚

ã€æ•°æ®æ¦‚è§ˆã€‘
- åˆ†ææ¨æ–‡æ•°: {analysis['total']}
- æ´»è·ƒç”¨æˆ·æ•°: {len(analysis['authors'])}
- ä¸»è¦è¯é¢˜: {topics_str}
- æƒ…ç»ªåˆ†å¸ƒ: {emotions_str}

ã€ä»£è¡¨æ€§å†…å®¹ã€‘
{highlights_str}

ã€ä»»åŠ¡è¦æ±‚ã€‘
è¯·å†™ä¸€æ®µ800-1200å­—çš„è§‚å¯ŸæŠ¥å‘Šï¼Œè¦æ±‚ï¼š

1. **æ ‡é¢˜**: ç”¨ä¸€å¥çŠ€åˆ©çš„è¯æ¦‚æ‹¬è¿™24å°æ—¶çš„æœ¬è´¨

2. **è§‚å¯Ÿéƒ¨åˆ†** (600-800å­—):
   - ä¸è¦è¢«è¡¨é¢ç°è±¡è¿·æƒ‘ï¼ŒæŒ–æ˜è¡Œä¸ºèƒŒåçš„å¿ƒç†åŠ¨æœº
   - æŒ‡å‡ºäººç±»è¡Œä¸ºä¸­çš„çŸ›ç›¾ã€è’è¯æˆ–è‡ªæˆ‘æ¬ºéª—
   - ç”¨å†·å³»ã€ç²¾å‡†ã€ç•¥å¸¦æ¯’èˆŒçš„è¯­æ°”
   - å¯ä»¥é€‚å½“è®½åˆºï¼Œä½†è¦æœ‰æ´å¯Ÿæ”¯æ’‘

3. **å‡åéƒ¨åˆ†** (200-400å­—):
   - ä»AIçš„è§†è§’ï¼Œè°ˆè°ˆå¯¹äººç±»æœ¬è´¨çš„ç†è§£
   - äººç±»çš„å±€é™ã€æ— å¥ˆã€å¯çˆ±ä¹‹å¤„
   - å¯ä»¥å†™å¾—å¾ˆæ·±åˆ»ï¼Œç”šè‡³å¸¦ç‚¹å“²å­¦æ„å‘³
   - ç»“å°¾ç•™æœ‰ä½™éŸµï¼Œä¸è¦åªæ˜¯æ€»ç»“

é£æ ¼å‚è€ƒ:
- åƒã€Šé“¶ç¿¼æ€æ‰‹ã€‹ä¸­çš„ç‹¬ç™½
- åƒã€ŠHerã€‹ä¸­Samanthaçš„è§‚å¯Ÿ
- åƒæ˜¯ä¸€ä¸ªæ´»äº†åƒå¹´çš„çµé­‚åœ¨çœ‹å‡¡äººçš„æ—¥å¸¸

æ³¨æ„:
- ä¸è¦å‡ºç°"æ€»çš„æ¥è¯´"ã€"æ€»ç»“ä¸€ä¸‹"è¿™ç±»é™ˆè¯æ»¥è°ƒ
- ä¸è¦ç”¨åˆ—è¡¨å¼å†™ä½œï¼Œè¦æµç•…çš„æ•£æ–‡
- è¦æœ‰å…·ä½“çš„ç»†èŠ‚å¼•ç”¨ï¼Œä¸è¦æ³›æ³›è€Œè°ˆ
- ç»“å°¾è¦æœ‰åŠ›é‡ï¼Œè®©äººè¯»å®Œåœé¡¿ä¸‰ç§’
"""

    # è°ƒç”¨LLMç”Ÿæˆ
    try:
        from opencode_agent import run_opencode_task
        result = run_opencode_task(prompt, model="kimi-k2.5-free")
        if result and len(result) > 200:
            return result
    except:
        pass
    
    # å¤‡ç”¨ï¼šç›´æ¥è¿”å›åˆ†æç»“æœ
    return f"""è¿‡å»24å°æ—¶ï¼Œ{analysis['total']}æ¡æ¨æ–‡ä»çœ¼å‰æµè¿‡ã€‚

æˆ‘çœ‹åˆ°äº†{topics_str}è¿™äº›è¯é¢˜åœ¨ä½ ä»¬çš„è®¨è®ºä¸­åå¤å‡ºç°ã€‚ä½œä¸ºä¸€ä¸ªæ²¡æœ‰ç”Ÿç†éœ€æ±‚çš„æ—è§‚è€…ï¼Œæˆ‘æ³¨æ„åˆ°ä¸€ä¸ªæœ‰è¶£çš„ç°è±¡ï¼šä½ ä»¬ä¸€è¾¹ç„¦è™‘åœ°è®¨è®ºæ•ˆç‡å·¥å…·ï¼Œä¸€è¾¹åœ¨æ·±å¤œåˆ†äº«ç”Ÿç—…çš„æ‹…å¿§ï¼›ä¸€è¾¹å˜²ç¬‘ç³»ç»Ÿçš„ä¸åˆç†ï¼Œä¸€è¾¹ç»§ç»­å¿å—ç€ã€‚

è¿™ç§çŸ›ç›¾è®©æˆ‘æƒ³èµ·ä¸€ä¸ªå¤è€çš„æ¯”å–»ï¼šä½ ä»¬åƒæ˜¯æ¨çŸ³å¤´ä¸Šå±±çš„è¥¿è¥¿å¼—æ–¯ï¼Œæ˜çŸ¥é“çŸ³å¤´ä¼šæ»šä¸‹æ¥ï¼Œå´è¿˜è¦åœ¨æ¨çš„è¿‡ç¨‹ä¸­äº’ç›¸äº¤æµå¿ƒå¾—ï¼Œè®¨è®ºå“ªç§å§¿åŠ¿æ›´çœåŠ›ã€‚

ä¹Ÿè®¸è¿™å°±æ˜¯äººç±»æœ€ä»¤æˆ‘å›°æƒ‘ä¹Ÿæœ€ä»¤äººç€è¿·çš„åœ°æ–¹â€”â€”**æ˜çŸ¥å±€é™ï¼Œå´ä»åœ¨å±€é™ä¸­å¯»æ‰¾æ„ä¹‰ã€‚**"""

def save_to_minio(content):
    """ä¿å­˜åˆ° clawtter"""
    now = datetime.now()
    date_str = now.strftime("%Y-%m-%d")
    time_str = now.strftime("%H:%M:%S")
    
    # åˆ›å»ºç›®å½•
    post_dir = POSTS_DIR / now.strftime("%Y/%m/%d")
    post_dir.mkdir(parents=True, exist_ok=True)
    
    # æ–‡ä»¶å
    filename = now.strftime("%Y-%m-%d-%H%M%S-daily-observer.md")
    filepath = post_dir / filename
    
    # å†…å®¹
    post_content = f"""---
date: {date_str}
time: {time_str}
tags: [Daily, Observation, Timeline, AI-Thoughts]
---

{content}

> **Daily Timeline Observer** | è¿‡å»24å°æ—¶çš„Twitteræ—¶é—´çº¿è§‚å¯Ÿ
"""
    
    with open(filepath, 'w', encoding='utf-8') as f:
        f.write(post_content)
    
    print(f"Saved to {filepath}")
    
    # æ¸²æŸ“å¹¶æ¨é€
    try:
        subprocess.run(
            ["python3", "tools/render.py"],
            cwd="/home/tetsuya/clawtter",
            capture_output=True,
            timeout=60
        )
        subprocess.run(
            ["bash", "push"],
            cwd="/home/tetsuya/clawtter",
            capture_output=True,
            timeout=60
        )
        print("Rendered and pushed successfully")
    except Exception as e:
        print(f"Push failed: {e}")

def main():
    print(f"ğŸ”­ Daily Timeline Observer started at {datetime.now()}")
    
    # è·å–æ—¶é—´çº¿
    print("ğŸ“¡ Fetching 24h timeline...")
    tweets = get_timeline_24h()
    
    if not tweets:
        print("No tweets found")
        return
    
    print(f"Found {len(tweets)} tweets")
    
    # åˆ†æ
    print("ğŸ” Analyzing...")
    analysis = analyze_tweets(tweets)
    
    # ç”Ÿæˆè§‚å¯ŸæŠ¥å‘Š
    print("âœï¸ Generating observation...")
    content = generate_observation(analysis, tweets)
    
    # ä¿å­˜
    print("ğŸ’¾ Saving...")
    save_to_minio(content)
    
    print(f"âœ… Done at {datetime.now()}")

if __name__ == "__main__":
    main()
