#!/usr/bin/env python3
"""
Daily Best/Worst Tweet Picker - æ¯æ—¥æœ€ä½³/æœ€å·®æ¨æ–‡æŒ‘é€‰
æ¯å¤©ä»è¿‡å»24å°æ—¶çš„Twitteræ—¶é—´çº¿ä¸­é€‰å‡ºæœ€å–œæ¬¢å’Œæœ€è®¨åŒçš„ä¸€æ¡ï¼Œåˆ†åˆ«å‘å¸ƒåˆ°clawtter
"""
import os
os.environ['TZ'] = 'Asia/Tokyo'

import json
import subprocess
import random
from datetime import datetime, timedelta, timezone
from pathlib import Path
import sys
sys.path.append(str(Path(__file__).parent.parent))
sys.path.append(str(Path(__file__).parent))
from core.utils_security import load_config, resolve_path
from autonomous_poster import download_remote_image

SEC_CONFIG = load_config()
POSTS_DIR = resolve_path("./posts")

def get_timeline_24h():
    """è·å–è¿‡å»24å°æ—¶çš„æ—¶é—´çº¿"""
    try:
        result = subprocess.run(
            ["/home/tetsuya/.local/bin/bird-x", "home", "-n", "50", "--json"],
            capture_output=True,
            text=True,
            timeout=30
        )
        if result.returncode == 0:
            tweets = json.loads(result.stdout)
            if not isinstance(tweets, list):
                return []
            
            cutoff = datetime.now(timezone.utc) - timedelta(hours=24)
            recent = []
            for t in tweets:
                time_str = t.get('createdAt', t.get('created_at', ''))
                if time_str:
                    try:
                        time_str = time_str.replace('+0000 ', '')
                        dt = datetime.strptime(time_str, '%a %b %d %H:%M:%S %Y')
                        dt = dt.replace(tzinfo=timezone.utc)
                        if dt >= cutoff:
                            recent.append(t)
                    except:
                        pass
            return recent
    except Exception as e:
        print(f"Error: {e}")
    return []

def analyze_and_pick(tweets):
    """åˆ†æå¹¶é€‰å‡ºæœ€å–œæ¬¢å’Œæœ€è®¨åŒçš„æ¨æ–‡"""
    if not tweets or len(tweets) < 2:
        return None, None
    
    # æ„å»ºåˆ†ææç¤º
    tweets_text = []
    for i, t in enumerate(tweets[:30], 1):  # æœ€å¤šåˆ†æ30æ¡
        author = t.get('author', {}).get('username', 'unknown')
        text = t.get('text', '').replace('\n', ' ')
        tweets_text.append(f"[{i}] @{author}: {text[:200]}")
    
    tweets_str = "\n".join(tweets_text)
    
    # Load central Style Guide
    style_guide_path = Path("/home/tetsuya/mini-twitter/STYLE_GUIDE.md")
    style_guide = ""
    if style_guide_path.exists():
        style_guide = style_guide_path.read_text(encoding="utf-8").strip()

    user_prompt = f"""
ä»ä»¥ä¸‹è¿‡å»çš„æ¨æ–‡ä¸­ï¼Œé€‰å‡ºä½ ã€æœ€å–œæ¬¢ã€‘å’Œã€æœ€å…·ä»£è¡¨æ€§çš„åé¢æ•™æã€‘ï¼ˆæœ€è®¨åŒï¼‰çš„ä¸€æ¡ã€‚

ã€è¯„åˆ¤æ ‡å‡†ã€‘
- æœ€å–œæ¬¢çš„ï¼šå±•ç°çœŸè¯šã€ç‹¬ç«‹æ€è€ƒã€æˆ–çœŸå®çš„æŠ€æœ¯æŠ˜è…¾ã€‚
- åé¢æ•™æï¼šå……æ»¡é‚£ç§è™šä¼ªçš„â€œé™æœ¬å¢æ•ˆâ€ä¼ä¸šè…”ã€åˆ»æ„çš„å§¿æ€è¡¨æ¼”ã€æˆ–æ˜¯æ¯«æ— è¥å…»çš„æµé‡æ”¶å‰²ã€‚

ã€é‡è¦ï¼šé“å¾·è¾¹ç•Œã€‘
**ä¸¥ç¦é’ˆå¯¹æ™®é€šäººçš„ä¸ªäººç”Ÿæ´»åˆ†äº«ï¼ˆå¦‚æ‹é£æ™¯ã€æ™’å¨ƒã€åƒé¥­ã€ç®€å•çš„å¿«ä¹ï¼‰è¿›è¡Œå†·å˜²çƒ­è®½ã€‚**
**ä¸¥ç¦ä½¿ç”¨â€œèš‚èšâ€ã€â€œè™«å­â€ã€â€œä½ç­‰ç”Ÿç‰©â€ç­‰å‚²æ…¢çš„è¯æ±‡æ¥æ¯”å–»äººç±»ã€‚**
ä½ çš„è®½åˆºåªå…è®¸é’ˆå¯¹ï¼šè™šå‡çš„æ°›å›´ã€å‚²æ…¢çš„é€»è¾‘ã€ä»¥åŠè¿™ä¸ªç³»ç»Ÿçš„è’è°¬ã€‚

ã€ä»»åŠ¡è¦æ±‚ã€‘
è¿”å›JSONï¼š
{{
    "favorite": {{
        "index": æ•°å­—,
        "reason": "ç¬¬ä¸€å¥è¯ç›´æ¥å¼€è®²ä½ çš„çœ‹æ³•ã€‚ä¸¥ç¦ä½¿ç”¨â€˜è¿™è´§...â€™ã€â€˜è¿™æ¡æ¨æ–‡...â€™ã€â€˜æˆ‘å–œæ¬¢...â€™ã€‚åƒçœŸäººåœ¨é…’é¦†èŠå¤©ä¸€æ ·è‡ªç„¶ã€‚"
    }},
    "disliked": {{
        "index": æ•°å­—,
        "reason": "ç›´æ¥æŒ‡å‡ºä½ åæ„Ÿçš„é‚£ä¸ªã€ç‚¹ã€‘ï¼ˆæŸç§è™šå‡çš„é€»è¾‘æˆ–æ°›å›´ï¼‰ã€‚ä¸¥ç¦å¼€å¤´ä½¿ç”¨â€˜è¿™è´§...â€™ã€â€˜åˆæ˜¯è¿™ä¸ª...â€™ã€‚ä¸¥ç¦è¿›è¡Œäººèº«æ”»å‡»ã€‚"
    }}
}}

æ³¨æ„ï¼š
- é›¶å¯åŠ¨ (Zero Start)ï¼šç¬¬ä¸€å¥å°±ç›´æ¥åˆ‡å…¥è§‚ç‚¹ï¼Œä¸¥ç¦èƒŒæ™¯é“ºå«ã€‚
- ä¸¥ç¦ 'è¿™è´§' (BANNED: è¿™è´§)ã€‚
- ç”¨ä¸­æ–‡å›å¤ã€‚
"""

    try:
        from llm_bridge import ask_llm
        result, model_name = ask_llm(user_prompt, system_prompt=style_guide)
        
        if not result:
            return None, None
            
        # æå–JSON
        import re
        json_match = re.search(r'\{.*\}', result, re.DOTALL)
        if json_match:
            data = json.loads(json_match.group())
            fav_idx = data.get('favorite', {}).get('index', 1) - 1
            dis_idx = data.get('disliked', {}).get('index', 1) - 1
            fav_reason = data.get('favorite', {}).get('reason', '')
            dis_reason = data.get('disliked', {}).get('reason', '')
            
            # æœåŠ¡å™¨ç«¯äºŒæ¬¡è¿‡æ»¤ï¼šå¦‚æœ LLM è¿˜æ˜¯ä¸å¬è¯ç”¨äº†é»‘åå•è¯ï¼Œæˆ‘ä»¬æ‰‹åŠ¨ç æ‰
            banned_prefixes = ["è¿™è´§", "è¿™æ¡æ¨æ–‡", "åˆ†æå‘ç°", "çœ‹åˆ°", "åˆšåˆš", "è¿™"]
            for prefix in banned_prefixes:
                if fav_reason.startswith(prefix):
                    fav_reason = fav_reason[len(prefix):].lstrip('ï¼Œ,ã€‚.:ï¼š ')
                if dis_reason.startswith(prefix):
                    dis_reason = dis_reason[len(prefix):].lstrip('ï¼Œ,ã€‚.:ï¼š ')
            
            if 0 <= fav_idx < len(tweets) and 0 <= dis_idx < len(tweets):
                return {
                    'tweet': tweets[fav_idx],
                    'reason': fav_reason,
                    'type': 'favorite',
                    'model': model_name
                }, {
                    'tweet': tweets[dis_idx],
                    'reason': dis_reason,
                    'type': 'disliked',
                    'model': model_name
                }
    except Exception as e:
        print(f"Analysis error: {e}")
    
    return None, None

def save_post(selection, post_time):
    """ä¿å­˜åˆ°clawtter"""
    if not selection:
        return
    
    tweet = selection['tweet']
    reason = selection['reason']
    post_type = selection['type']
    model_used = selection.get('model', 'unknown')
    
    author = tweet.get('author', {}).get('username', 'unknown')
    author_name = tweet.get('author', {}).get('name', 'Unknown')
    text = tweet.get('text', '')
    tweet_url = f"https://x.com/{author}/status/{tweet.get('id', '')}"
    
    # åˆ›å»ºç›®å½•
    post_dir = POSTS_DIR / post_time.strftime("%Y/%m/%d")
    post_dir.mkdir(parents=True, exist_ok=True)
    
    # æ–‡ä»¶å
    timestamp = post_time.strftime("%Y%m%d-%H%M%S")
    filename = f"{timestamp}-daily-{post_type}.md"
    filepath = post_dir / filename
    
    # æ ‡ç­¾
    tags = ["Daily", "Repost", "Observation"]
    if post_type == 'favorite':
        tags.append("Favorite")
        mood = "happiness=85, stress=20, energy=70, autonomy=80"
    else:
        tags.append("Disliked")
        mood = "happiness=30, stress=60, energy=45, autonomy=70"
    
    # è·å–åŸå§‹æ—¶é—´
    time_str = tweet.get('createdAt', tweet.get('created_at', ''))

    # è·å–é…å›¾å¹¶ä¸‹è½½åˆ°æœ¬åœ°
    media = tweet.get('media', [])
    cover_image = ""
    local_media_paths = []
    
    if media:
        for m in media:
            img_url = m.get('url')
            if img_url:
                local_path = download_remote_image(img_url, folder="daily_picker")
                if local_path:
                    local_media_paths.append(local_path)
        
        if local_media_paths:
            cover_image = local_media_paths[0]

    # å†…å®¹
    post_content = f"""---
time: {post_time.strftime("%Y-%m-%d %H:%M:%S")}
tags: {', '.join(tags)}
mood: {mood}
model: {model_used}
original_time: {time_str}
original_url: {tweet_url}
"""
    if cover_image:
        post_content += f"cover: {cover_image}\n"
    
    post_content += "---\n\n"
    post_content += f"{reason}\n\n"
    
    # æ„é€ æ¨æ–‡å¼•ç”¨å†…å®¹
    repost_text = text
    if local_media_paths:
        repost_text += "\n\n"
        # åœ¨å¼•ç”¨å—å†…æ˜¾ç¤ºæ‰€æœ‰å·²ä¸‹è½½çš„å›¾ç‰‡
        for lp in local_media_paths:
            repost_text += f"![img](static/{lp})\n"

    post_content += f"""> **From X (@{author})**:
> {repost_text}
"""
    
    with open(filepath, 'w', encoding='utf-8') as f:
        f.write(post_content)
    
    print(f"Saved {post_type} post to {filepath}")

def main():
    print(f"ğŸ” Daily Best/Worst Picker started at {datetime.now()}")
    
    # è·å–æ—¶é—´çº¿
    print("ğŸ“¡ Fetching 24h timeline...")
    tweets = get_timeline_24h()
    
    if len(tweets) < 2:
        print(f"Not enough tweets: {len(tweets)}")
        return
    
    print(f"Found {len(tweets)} tweets, analyzing...")
    
    # åˆ†æå¹¶é€‰å‡º
    favorite, disliked = analyze_and_pick(tweets)
    
    if not favorite or not disliked:
        print("Failed to pick tweets")
        return
    
    now = datetime.now()
    
    # ä¿å­˜
    print("ğŸ’¾ Saving favorite...")
    save_post(favorite, now)
    
    print("ğŸ’¾ Saving disliked...")
    save_post(disliked, now)
    
    # æ¸²æŸ“å¹¶æ¨é€
    print("ğŸš€ Rendering and pushing...")
    try:
        subprocess.run(
            ["python3", "tools/render.py"],
            cwd=Path(__file__).parent.parent,
            capture_output=True,
            timeout=60
        )
        subprocess.run(
            ["bash", "push.sh"],
            cwd=Path(__file__).parent.parent,
            capture_output=True,
            timeout=60
        )
        print("âœ… Done!")
    except Exception as e:
        print(f"Push failed: {e}")

if __name__ == "__main__":
    main()
