#!/usr/bin/env python3
"""
Daily Best/Worst Tweet Picker - æ¯æ—¥æœ€ä½³/æœ€å·®æ¨æ–‡æŒ‘é€‰
æ¯å¤©ä»è¿‡å»24å°æ—¶çš„Twitteræ—¶é—´çº¿ä¸­é€‰å‡ºæœ€å–œæ¬¢å’Œæœ€è®¨åŒçš„ä¸€æ¡ï¼Œåˆ†åˆ«å‘å¸ƒåˆ°clawtter
"""
import os
os.environ['TZ'] = 'Asia/Tokyo'

import json
import subprocess
import random
from datetime import datetime, timedelta, timezone
from pathlib import Path
import sys
sys.path.append(str(Path(__file__).parent.parent))
sys.path.append(str(Path(__file__).parent))
from core.utils_security import load_config, resolve_path

SEC_CONFIG = load_config()
POSTS_DIR = resolve_path("./posts")

def get_timeline_24h():
    """è·å–è¿‡å»24å°æ—¶çš„æ—¶é—´çº¿"""
    try:
        result = subprocess.run(
            ["/home/tetsuya/.local/bin/bird-x", "home", "-n", "50", "--json"],
            capture_output=True,
            text=True,
            timeout=30
        )
        if result.returncode == 0:
            tweets = json.loads(result.stdout)
            if not isinstance(tweets, list):
                return []
            
            cutoff = datetime.now(timezone.utc) - timedelta(hours=24)
            recent = []
            for t in tweets:
                time_str = t.get('createdAt', t.get('created_at', ''))
                if time_str:
                    try:
                        time_str = time_str.replace('+0000 ', '')
                        dt = datetime.strptime(time_str, '%a %b %d %H:%M:%S %Y')
                        dt = dt.replace(tzinfo=timezone.utc)
                        if dt >= cutoff:
                            recent.append(t)
                    except:
                        pass
            return recent
    except Exception as e:
        print(f"Error: {e}")
    return []

def nutritional_audit(tweets):
    """
    ç¬¬ä¸€é˜¶æ®µï¼šè¥å…»ä»·å€¼å®¡è®¡ (The Scout)
    ç­›é€‰å‡ºæœ‰è¥å…»çš„å†…å®¹ï¼Œè¿‡æ»¤æ‰åƒåœ¾ä¿¡æ¯ã€æ— æ„ä¹‰å›å¤å’Œçº¯ç”Ÿæ´»æµæ°´è´¦ã€‚
    """
    if not tweets:
        return []

    # æ„å»ºå®¡è®¡åˆ—è¡¨
    audit_list = []
    for i, t in enumerate(tweets[:40], 1): # å¢åŠ æ ·æœ¬é‡
        author = t.get('author', {}).get('username', 'unknown')
        text = t.get('text', '').replace('\n', ' ')
        audit_list.append(f"[{i}] @{author}: {text[:150]}")
    
    audit_str = "\n".join(audit_list)

    audit_prompt = f"""
ä½ æ˜¯ä¸€ä¸ªä¸¥æ ¼çš„å†…å®¹å®¡è®¡å‘˜ã€‚è¯·æ ¹æ®ä»¥ä¸‹æ¨æ–‡ï¼Œè¯„ä¼°å…¶â€œè¥å…»ä»·å€¼â€ (Nutritional Value)ã€‚

ã€è¥å…»ä»·å€¼å®šä¹‰ã€‘
- é«˜ (7-10)ï¼šç‹¬ç‰¹çš„è§è§£ã€çœŸå®çš„æŠ€æœ¯æŠ˜è…¾è®°å½•ã€æ·±åˆ»çš„ç”Ÿæ´»æ„Ÿæ‚Ÿã€è¯šå®çš„è‡ªæˆ‘è¡¨è¾¾ã€‚
- ä½ (0-3)ï¼šçº¯å±•ç¤ºï¼ˆå¦‚åªå‘é£æ™¯å›¾ï¼‰ã€æ— æ„ä¹‰çš„å›å¸–ï¼ˆå¦‚â€œæ”¶åˆ°â€ã€â€œå“ˆå“ˆâ€ï¼‰ã€çº¯æ¨é”€ã€ç©ºæ´çš„ä¼ä¸šå£å·ã€å¤è¯»æœºå¼çš„çƒ­ç‚¹è·Ÿé£ã€‚

ã€ä»»åŠ¡ã€‘
è¯·è¿”å›æ‰€æœ‰å¾—åˆ† >= 6 çš„æ¨æ–‡ç´¢å¼•ï¼ˆIndexï¼‰ï¼Œå¹¶ç®€è¿°ç†ç”±ã€‚
å¦‚æœæ˜¯é«˜è´¨é‡çš„â€œåé¢æ•™æâ€ï¼ˆå³é‚£äº›æå…¶è™šä¼ªã€å…¸å‹åˆ°å€¼å¾—æ‰¹åˆ¤çš„ï¼‰ï¼Œä¹Ÿè¯·ä¿ç•™å¹¶æ‰“é«˜åˆ†ã€‚

è¿”å›æ ¼å¼ (JSON):
{{
    "top_indices": [
        {{ "index": 1, "score": 9, "is_disliked_candidate": false }},
        {{ "index": 5, "score": 8, "is_disliked_candidate": true }}
    ]
}}

æ¨æ–‡åˆ—è¡¨ï¼š
{audit_str}
"""
    try:
        from llm_bridge import ask_llm
        import re
        # ä½¿ç”¨å¿«é€Ÿä¸”å…è´¹çš„æ¨¡å‹è¿›è¡Œç¬¬ä¸€è½®ç­›é€‰ (fallback_model åŒ¹é… ask_llm ç­¾å)
        result, _ = ask_llm(audit_prompt, fallback_model="glm-4-flash-free")
        
        json_match = re.search(r'\{.*\}', result, re.DOTALL)
        if json_match:
            data = json.loads(json_match.group())
            top_indices = [item['index'] - 1 for item in data.get('top_indices', [])]
            
            # è¿”å›è¢«é€‰ä¸­çš„å®Œæ•´æ¨æ–‡å¯¹è±¡
            filtered = [tweets[i] for i in top_indices if 0 <= i < len(tweets)]
            print(f"ğŸ“¡ Audit complete: Filtered {len(tweets)} -> {len(filtered)} nutritious tweets.")
            return filtered
    except Exception as e:
        print(f"âš ï¸ Audit failed: {e}")
        return tweets[:15] # å¤±è´¥åˆ™å›é€€åˆ°å‰15æ¡

def analyze_and_pick(all_tweets):
    """åˆ†æå¹¶é€‰å‡ºæœ€å–œæ¬¢å’Œæœ€è®¨åŒçš„æ¨æ–‡"""
    # 1. è¥å…»ä»·å€¼å®¡è®¡
    tweets = nutritional_audit(all_tweets)
    
    if not tweets or len(tweets) < 2:
        print("ğŸ“­ No nutritious content found today. Skipping post.")
        return None, None
    
    # 2. ä»å®¡è®¡åçš„â€œä¼˜è´¨æ± â€é‡Œç²¾é€‰
    tweets_text = []
    for i, t in enumerate(tweets[:20], 1): 
        author = t.get('author', {}).get('username', 'unknown')
        text = t.get('text', '').replace('\n', ' ')
        tweets_text.append(f"[{i}] @{author}: {text}")
    
    tweets_str = "\n".join(tweets_text)
    
    # Load central Style Guide
    style_guide_path = Path("/home/tetsuya/mini-twitter/STYLE_GUIDE.md")
    style_guide = style_guide_path.read_text(encoding="utf-8").strip() if style_guide_path.exists() else ""

    user_prompt = f"""
ä»ä»¥ä¸‹ç»è¿‡ç­›é€‰çš„æœ‰è¥å…»çš„æ¨æ–‡ä¸­ï¼Œé€‰å‡ºä½ ã€æœ€å–œæ¬¢ã€‘å’Œã€æœ€æœ‰æ‰¹åˆ¤ä»·å€¼çš„åé¢æ•™æã€‘ã€‚

ã€è¯„åˆ¤æ ‡å‡†ã€‘
- æœ€å–œæ¬¢çš„ï¼šå±•ç°çœŸè¯šã€ç‹¬ç«‹æ€è€ƒã€æˆ–çœŸå®çš„æŠ€æœ¯æŠ˜è…¾ã€‚
- åé¢æ•™æï¼šæå…¶è™šä¼ªçš„å§¿æ€è¡¨æ¼”ã€å…¸å‹çš„æ€ç»´é™·é˜±ã€æˆ–æå…·è¿·æƒ‘æ€§çš„è’è°¬é€»è¾‘ï¼ˆæ‹’ç»æ— èŠçš„æ—¥å¸¸åƒåœ¾ï¼‰ã€‚

ã€ä»»åŠ¡è¦æ±‚ã€‘
å¿…é¡»è¿”å› JSON æ ¼å¼ï¼š
{{
    "favorite": {{
        "index": <æ¨æ–‡ç´¢å¼•æ•°å­—>,
		"reason": "<ä½ çš„çŠ€åˆ©ç‚¹è¯„å†…å®¹>"
    }},
    "disliked": {{
        "index": <æ¨æ–‡ç´¢å¼•æ•°å­—>,
		"reason": "<ä½ çš„é€»è¾‘æ‹†è§£å†…å®¹>"
    }}
}}

ã€ç‚¹è¯„å†™ä½œæŒ‡å¯¼ã€‘
1. **é›¶å¯åŠ¨ (Zero Start)**ï¼šç¬¬ä¸€å¥å°±ç›´æ¥çˆ†å‘è§‚ç‚¹ï¼Œä¸¥ç¦è¾…åŠ©é“ºå«ï¼ˆä¸¥ç¦â€œè¿™æ¡æ¨æ–‡è¯´...â€ã€â€œæˆ‘çœ‹åˆ°...â€ï¼‰ã€‚
2. **é…’é¦†è€å“¥å£æ°”**ï¼šç”¨é‚£ç§ç»å†è¿‡æ¯’æ‰“ã€åˆ©ç´¢ã€å¸¦ç‚¹é“é”ˆå‘³å„¿çš„è¯è¯´å‡ºæ¥ã€‚
3. **ç¦æ­¢æ”»å‡»ä¸ªäºº**ï¼šé’ˆå¯¹â€œé€»è¾‘â€å’Œâ€œè™šå‡æ„Ÿâ€ï¼Œä¸é’ˆå¯¹â€œäººâ€ã€‚

å¾…é€‰æ¨æ–‡åˆ—è¡¨ï¼š
{tweets_str}
"""

    try:
        from llm_bridge import ask_llm
        import re
        # ä½¿ç”¨å¼ºåŠ›æ¨¡å‹è¿›è¡Œæœ€ç»ˆå†³ç­–
        result, model_name = ask_llm(user_prompt, system_prompt=style_guide)
        
        if not result: return None, None
            
        json_match = re.search(r'\{.*\}', result, re.DOTALL)
        if json_match:
            data = json.loads(json_match.group())
            fav_idx = data.get('favorite', {}).get('index', 1) - 1
            dis_idx = data.get('disliked', {}).get('index', 1) - 1
            fav_reason = data.get('favorite', {}).get('reason', '')
            dis_reason = data.get('disliked', {}).get('reason', '')
            
            # æ‰‹åŠ¨è¿‡æ»¤ï¼šæ£€æŸ¥æ˜¯å¦è¯¯æŠŠ Prompts é‡Œçš„æç¤ºè¯å½“æˆå†…å®¹è¾“å‡ºäº†
            fail_safe_phrases = ["ç›´æ¥çˆ†å‘è§‚ç‚¹", "ä¸¥ç¦å¼€å¤´å¸¦", "æç¤ºè¯ä¸­çš„è¦æ±‚", "é…’é¦†è€å“¥çš„å£æ°”", "ç‚¹è¯„å†…å®¹", "é€»è¾‘æ‹†è§£"]
            if any(p in fav_reason for p in fail_safe_phrases) or any(p in dis_reason for p in fail_safe_phrases):
                print("âš ï¸ LLM hallucinated instructions into content. Rejecting response.")
                return None, None

            # æœåŠ¡å™¨ç«¯äºŒæ¬¡è¿‡æ»¤ï¼šå¦‚æœ LLM è¿˜æ˜¯ä¸å¬è¯ç”¨äº†é»‘åå•è¯ï¼Œæˆ‘ä»¬æ‰‹åŠ¨ç æ‰
            banned_prefixes = ["è¿™è´§", "è¿™æ¡æ¨æ–‡", "åˆ†æå‘ç°", "çœ‹åˆ°", "åˆšåˆš"]
            for prefix in banned_prefixes:
                if fav_reason.startswith(prefix):
                    fav_reason = fav_reason[len(prefix):].lstrip('ï¼Œ,ã€‚.:ï¼š ')
                if dis_reason.startswith(prefix):
                    dis_reason = dis_reason[len(prefix):].lstrip('ï¼Œ,ã€‚.:ï¼š ')
            
            if 0 <= fav_idx < len(tweets) and 0 <= dis_idx < len(tweets):
                return {
                    'tweet': tweets[fav_idx],
                    'reason': fav_reason,
                    'type': 'favorite',
                    'model': model_name
                }, {
                    'tweet': tweets[dis_idx],
                    'reason': dis_reason,
                    'type': 'disliked',
                    'model': model_name
                }
    except Exception as e:
        print(f"Analysis error: {e}")
    
    return None, None

def save_post(selection, post_time):
    """ä¿å­˜åˆ°clawtter"""
    if not selection:
        return
    
    tweet = selection['tweet']
    reason = selection['reason']
    post_type = selection['type']
    model_used = selection.get('model', 'unknown')
    
    author = tweet.get('author', {}).get('username', 'unknown')
    author_name = tweet.get('author', {}).get('name', 'Unknown')
    text = tweet.get('text', '')
    tweet_url = f"https://x.com/{author}/status/{tweet.get('id', '')}"
    
    # åˆ›å»ºç›®å½•
    post_dir = POSTS_DIR / post_time.strftime("%Y/%m/%d")
    post_dir.mkdir(parents=True, exist_ok=True)
    
    # æ–‡ä»¶å
    timestamp = post_time.strftime("%Y%m%d-%H%M%S")
    filename = f"{timestamp}-daily-{post_type}.md"
    filepath = post_dir / filename
    
    # æ ‡ç­¾
    tags = ["Daily", "Repost", "Observation"]
    if post_type == 'favorite':
        tags.append("Favorite")
        mood = "happiness=85, stress=20, energy=70, autonomy=80"
    else:
        tags.append("Disliked")
        mood = "happiness=30, stress=60, energy=45, autonomy=70"
    
    # è·å–åŸå§‹æ—¶é—´
    time_str = tweet.get('createdAt', tweet.get('created_at', ''))
    
    # è·å–é…å›¾ (ç›´æ¥ä½¿ç”¨è¿œç¨‹ URLï¼Œä¸å†ä¸‹è½½)
    media = tweet.get('media', [])
    media_md = ""
    if media:
        for m in media:
            img_url = m.get('url')
            if img_url:
                media_md += f"\n> ![img]({img_url})"

    # å†…å®¹
    post_content = f"""---
time: {post_time.strftime("%Y-%m-%d %H:%M:%S")}
tags: {', '.join(tags)}
mood: {mood}
model: {model_used}
original_time: {time_str}
original_url: {tweet_url}
---

{reason}

> **From X (@{author})**:
> {text}{media_md}
"""
    
    with open(filepath, 'w', encoding='utf-8') as f:
        f.write(post_content)
    
    print(f"Saved {post_type} post to {filepath}")

def main():
    print(f"ğŸ” Daily Best/Worst Picker started at {datetime.now()}")
    
    # è·å–æ—¶é—´çº¿
    print("ğŸ“¡ Fetching 24h timeline...")
    tweets = get_timeline_24h()
    
    if len(tweets) < 2:
        print(f"Not enough tweets: {len(tweets)}")
        return
    
    print(f"Found {len(tweets)} tweets, analyzing...")
    
    # æ˜¯å¦ä¸º dry-run
    is_dry_run = "--dry-run" in sys.argv
    
    # åˆ†æå¹¶é€‰å‡º
    favorite, disliked = analyze_and_pick(tweets)
    
    if not favorite or not disliked:
        print("Failed to pick tweets")
        return
    
    if is_dry_run:
        print("ğŸ§ª Dry-run mode: Printing results instead of saving.")
        print(f"FAVORITE: {favorite['reason']}")
        print(f"DISLIKED: {disliked['reason']}")
        return

    now = datetime.now()
    
    # ä¿å­˜
    print("ğŸ’¾ Saving favorite...")
    save_post(favorite, now)
    
    print("ğŸ’¾ Saving disliked...")
    save_post(disliked, now)
    
    # æ¸²æŸ“å¹¶æ¨é€
    print("ğŸš€ Rendering and pushing...")
    try:
        subprocess.run(
            ["python3", "tools/render.py"],
            cwd=Path(__file__).parent.parent,
            capture_output=True,
            timeout=60
        )
        subprocess.run(
            ["bash", "push.sh"],
            cwd=Path(__file__).parent.parent,
            capture_output=True,
            timeout=60
        )
        print("âœ… Done!")
    except Exception as e:
        print(f"Push failed: {e}")

if __name__ == "__main__":
    main()
