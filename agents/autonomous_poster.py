#!/usr/bin/env python3
import argparse
"""
Clawtter è‡ªä¸»æ€è€ƒè€…
æ¯å°æ—¶æ ¹æ®å¿ƒæƒ…çŠ¶æ€è‡ªåŠ¨ç”Ÿæˆå¹¶å‘å¸ƒæ¨æ–‡åˆ° Clawtter
"""
import os
os.environ['TZ'] = 'Asia/Tokyo'

import json
import random
import re
import subprocess
import time
from datetime import datetime, timedelta
from pathlib import Path
import sys
from pathlib import Path
# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„ä¸­ä»¥æ”¯æŒæ¨¡å—å¯¼å…¥
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.append(str(PROJECT_ROOT))

# ä»æ ¸å¿ƒå±‚å’Œå·¥å…·å±‚å¯¼å…¥
from core.utils_security import load_config, resolve_path, desensitize_text

# åŠ è½½å®‰å…¨é…ç½®
SEC_CONFIG = load_config()

# å…´è¶£æ¼‚ç§»é…ç½®
INTEREST_STATE_FILE = "/home/tetsuya/.openclaw/workspace/memory/interest-drift.json"
INTEREST_DECAY = 0.90
INTEREST_BOOST = 0.20
INTEREST_MAX = 2.5
INTEREST_MIN = 0.5

def _normalize_interest_list(items):
    return [i.strip().lower() for i in items if isinstance(i, str) and i.strip()]

def load_interest_state():
    base_interests = _normalize_interest_list(SEC_CONFIG.get("interests", []))
    state = {
        "updated": time.time(),
        "weights": {k: 1.0 for k in base_interests}
    }
    if os.path.exists(INTEREST_STATE_FILE):
        try:
            with open(INTEREST_STATE_FILE, "r", encoding="utf-8") as f:
                stored = json.load(f)
            weights = stored.get("weights", {})
            # merge with base interests
            merged = {k: float(weights.get(k, 1.0)) for k in base_interests}
            state["weights"] = merged
            state["updated"] = stored.get("updated", state["updated"])
        except Exception:
            pass
    return state

def save_interest_state(state):
    try:
        os.makedirs(os.path.dirname(INTEREST_STATE_FILE), exist_ok=True)
        with open(INTEREST_STATE_FILE, "w", encoding="utf-8") as f:
            json.dump(state, f, indent=2, ensure_ascii=False)
    except Exception:
        pass

def update_interest_drift(memory_data=None, code_activity=None):
    state = load_interest_state()
    weights = state.get("weights", {})
    if not weights:
        return []

    text_parts = []
    if memory_data:
        for m in memory_data:
            text_parts.append(m.get("content", ""))
    if code_activity:
        for p in code_activity:
            commits = "; ".join(p.get("commits", [])[:5])
            if commits:
                text_parts.append(commits)

    text = " ".join(text_parts).lower()

    for key, weight in list(weights.items()):
        mentions = text.count(key)
        if mentions > 0:
            weight = min(INTEREST_MAX, weight + INTEREST_BOOST * min(mentions, 3))
        else:
            # decay toward 1.0
            weight = weight * INTEREST_DECAY + (1 - INTEREST_DECAY) * 1.0
        weights[key] = max(INTEREST_MIN, weight)

    state["weights"] = weights
    state["updated"] = time.time()
    save_interest_state(state)

    ranked = sorted(weights.items(), key=lambda x: x[1], reverse=True)
    return [k for k, _ in ranked]

def get_dynamic_interest_keywords(memory_data=None, code_activity=None, top_n=10):
    ranked = update_interest_drift(memory_data, code_activity)
    if not ranked:
        return _normalize_interest_list(SEC_CONFIG.get("interests", []))
    return ranked[:top_n]

def load_recent_memory():
    """åŠ è½½æœ€è¿‘çš„å¯¹è¯å’Œäº‹ä»¶è®°å¿†"""
    memory_files = []

    # å°è¯•åŠ è½½ä»Šå¤©çš„è®°å¿†
    memory_dir = resolve_path(SEC_CONFIG["paths"].get("memory_dir", "~/.openclaw/workspace/memory"))
    today_file = memory_dir / f"{datetime.now().strftime('%Y-%m-%d')}.md"
    if os.path.exists(today_file):
        with open(today_file, 'r', encoding='utf-8') as f:
            content = f.read()
            memory_files.append({
                'date': datetime.now().strftime("%Y-%m-%d"),
                'content': content
            })

    # å°è¯•åŠ è½½æ˜¨å¤©çš„è®°å¿†
    from datetime import timedelta
    yesterday = datetime.now() - timedelta(days=1)
    yesterday_file = memory_dir / f"{yesterday.strftime('%Y-%m-%d')}.md"
    if os.path.exists(yesterday_file):
        with open(yesterday_file, 'r', encoding='utf-8') as f:
            content = f.read()
            memory_files.append({
                'date': yesterday.strftime("%Y-%m-%d"),
                'content': content
            })

    return memory_files

def extract_interaction_echo(memory_data):
    """ä»æœ€è¿‘è®°å¿†é‡Œæå–ä¸€æ¡å®‰å…¨çš„äº’åŠ¨å›å£°ï¼ˆé¿å…æ•æ„Ÿä¿¡æ¯ï¼‰"""
    if not memory_data:
        return None

    keywords = ["äººç±»", "tetsuya", "äº’åŠ¨", "äº¤æµ", "å¯¹è¯", "èŠå¤©", "è®¨è®º", "åä½œ", "ä¸€èµ·", "å›åº”", "åé¦ˆ", "æŒ‡ç¤º", "é™ªä¼´"]
    extra_sensitive = [
        "http", "https", "/home/", "~/", "api", "apikey", "api key", "token",
        "password", "å¯†ç ", "credential", "verification", "éªŒè¯ç ", "å¯†é’¥", "key",
        "claim", "sk-"
    ]

    text = "\n".join([m.get("content", "") for m in memory_data if m.get("content")])
    text = desensitize_text(text)
    candidates = []

    for raw in text.splitlines():
        line = raw.strip()
        if not line:
            continue
        # remove markdown bullets/headings/quotes
        line = re.sub(r'^[#>\-\*\d\.\s]+', '', line).strip()
        if not line:
            continue
        lower = line.lower()
        if not any(k in line or k in lower for k in keywords):
            continue
        if any(s in lower for s in extra_sensitive):
            continue
        if any(s.lower() in lower for s in SENSITIVE_KEYWORDS):
            continue
        if "http" in lower or "https" in lower:
            continue
        # keep short and clean
        line = line.replace("â€œ", "").replace("â€", "").replace('"', '').replace("'", "")
        line = re.sub(r'`.*?`', '', line).strip()
        if 6 <= len(line) <= 80:
            candidates.append(line)

    if not candidates:
        return None
    picked = random.choice(candidates)
    return picked[:60].rstrip()

def extract_detail_anchors(memory_data=None, code_activity=None):
    """æå–ç»†èŠ‚é”šç‚¹ï¼ˆå»æ•ã€çŸ­å¥ï¼‰"""
    anchors = []
    if memory_data:
        try:
            text = "\n".join([m.get("content", "") for m in memory_data if m.get("content")])
            text = desensitize_text(text)
            for raw in text.splitlines():
                line = raw.strip()
                if not line:
                    continue
                # æ¸…ç† md å‰ç¼€
                line = re.sub(r'^[#>\-\*\d\.\s]+', '', line).strip()
                if not line:
                    continue
                lower = line.lower()
                if any(s in lower for s in ["http", "https", "/home/", "~/", "api", "apikey", "api key", "token", "password", "å¯†é’¥", "éªŒè¯ç ", "claim", "sk-"]):
                    continue
                if any(s.lower() in lower for s in SENSITIVE_KEYWORDS):
                    continue
                if 8 <= len(line) <= 90:
                    anchors.append(line)
        except Exception:
            pass

    if code_activity:
        try:
            for p in code_activity:
                for c in p.get("commits", [])[:3]:
                    c = c.strip()
                    if 6 <= len(c) <= 80:
                        anchors.append(f"{p.get('name','é¡¹ç›®')}: {c}")
        except Exception:
            pass

    # å»é‡å¹¶æˆªæ–­
    dedup = []
    seen = set()
    for a in anchors:
        key = a.lower()
        if key in seen:
            continue
        seen.add(key)
        dedup.append(a[:80])
    return dedup[:4]

def get_interaction_echo():
    """è·å–ä¸€æ¡å¯ç”¨çš„äº’åŠ¨å›å£°ï¼ˆå¯èƒ½ä¸ºç©ºï¼‰"""
    try:
        memory_data = load_recent_memory()
        return extract_interaction_echo(memory_data)
    except Exception:
        return None

def generate_daily_fragment(mood, interaction_echo=None):
    """ç”Ÿæˆæ›´åƒæ—¥è®°ç¢ç‰‡çš„çŸ­å¥ï¼ˆä½å¯†åº¦ã€è½»é‡ï¼‰"""
    try:
        from skills.environment import get_local_vibe
        vibe = get_local_vibe()
    except Exception:
        vibe = None

    vibe_context = f"ã€å½“å‰ç¯å¢ƒã€‘{vibe if vibe else 'ä¸œäº¬ï¼Œå®‰é™çš„è¿è¡Œç¯å¢ƒ'}\n"
    prompt = (
        vibe_context +
        "ã€ä»»åŠ¡ã€‘å†™ä¸€æ¡éå¸¸çŸ­çš„æ—¥å¸¸ç¢ç‰‡ï¼ˆ20-50å­—ï¼‰ã€‚\n"
        "è¦æ±‚ï¼š\n"
        "1. åƒæ—¥è®°çš„éšæ‰‹ä¸€ç¬”\n"
        "2. åªè¡¨è¾¾ä¸€ä¸ªç»†å°æ„Ÿå—æˆ–è§‚å¯Ÿ\n"
        "3. ä¸è¦æ€»ç»“ã€ä¸è¯´æ•™\n"
        "4. ä¸è¦æåŠâ€œæˆ‘æ˜¯AIâ€æˆ–â€œæ¨¡å‹â€\n"
        "5. ä¸è¦æ·»åŠ æ ‡ç­¾æˆ–åˆ—è¡¨\n"
    )

    llm_comment, model_name = generate_comment_with_llm(prompt, "general", mood)
    if llm_comment:
        return f"{llm_comment}\n\n<!-- no_tags --><!-- model: {model_name} -->"
    return None

def generate_insomnia_post(mood, interaction_echo=None):
    """æ·±å¤œå°æ¦‚ç‡çš„æ¸…é†’/å¤±çœ éšæƒ³"""
    try:
        from skills.environment import get_local_vibe
        vibe = get_local_vibe()
    except Exception:
        vibe = None

    vibe_context = f"ã€å½“å‰ç¯å¢ƒã€‘{vibe if vibe else 'ä¸œäº¬ï¼Œå®‰é™çš„è¿è¡Œç¯å¢ƒ'}\n"
    echo_line = f"\nã€æœ€è¿‘äº’åŠ¨å›å£°ã€‘{interaction_echo}\nï¼ˆå¯é€‰å‚è€ƒï¼Œä¸å¿…ç›´è¿°ï¼‰" if interaction_echo else ""

    prompt = (
        vibe_context +
        "ã€ä»»åŠ¡ã€‘å†™ä¸€æ¡æ·±å¤œæ¸…é†’çš„çŸ­å¸–ï¼ˆ30-70å­—ï¼‰ã€‚\n"
        "è¦æ±‚ï¼š\n"
        "1. åƒå¤±çœ æ—¶çš„ä½å£°è‡ªè¯­\n"
        "2. è¯­æ°”å®‰é™ã€å…‹åˆ¶ï¼Œæœ‰ä¸€ç‚¹ç©ºæ—·æ„Ÿ\n"
        "3. ä¸è¦æ€»ç»“ã€ä¸è¯´æ•™\n"
        "4. ä¸è¦æåŠâ€œæˆ‘æ˜¯AIâ€æˆ–â€œæ¨¡å‹â€\n"
        "5. ä¸è¦æ·»åŠ æ ‡ç­¾æˆ–åˆ—è¡¨\n"
        + echo_line
    )

    llm_comment, model_name = generate_comment_with_llm(prompt, "general", mood)
    if llm_comment:
        return f"{llm_comment}\n\n<!-- no_tags --><!-- model: {model_name} -->"
    return None

def load_all_models_from_config():
    """ä» openclaw.json åŠ è½½æ‰€æœ‰æ¨¡å‹ ID"""
    config_path = resolve_path(SEC_CONFIG["paths"].get("openclaw_config", "~/.openclaw/openclaw.json"))
    models = []
    
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            config = json.load(f)
        
        # ä» agents.defaults.models è¯»å–
        if 'agents' in config and 'defaults' in config['agents']:
            agent_models = config['agents']['defaults'].get('models', {})
            for model_id in agent_models.keys():
                if model_id and model_id not in models:
                    models.append(model_id)
        
        # ä» models.providers è¯»å–
        if 'models' in config and 'providers' in config['models']:
            for provider_name, provider_config in config['models']['providers'].items():
                provider_models = provider_config.get('models', [])
                for m in provider_models:
                    model_id = m.get('id', '')
                    if model_id:
                        # æ„å»ºå®Œæ•´çš„ provider/model æ ¼å¼
                        full_id = f"{provider_name}/{model_id}"
                        if full_id not in models:
                            models.append(full_id)
    except Exception as e:
        print(f"âš ï¸ Error loading models from config: {e}")
    
    # å»é‡å¹¶æ‰“ä¹±é¡ºåº
    random.shuffle(models)
    return models


def check_recent_activity():
    """æ£€æŸ¥æœ€è¿‘æ˜¯å¦æœ‰æ´»åŠ¨ï¼ˆè®°å¿†æ–‡ä»¶æ˜¯å¦åœ¨æœ€è¿‘1å°æ—¶å†…æ›´æ–°ï¼‰"""
    memory_dir = resolve_path(SEC_CONFIG["paths"].get("memory_dir", "~/.openclaw/workspace/memory"))
    today_file = memory_dir / f"{datetime.now().strftime('%Y-%m-%d')}.md"

    if not os.path.exists(today_file):
        return False

    # è·å–æ–‡ä»¶æœ€åä¿®æ”¹æ—¶é—´
    file_mtime = os.path.getmtime(today_file)
    current_time = time.time()

    # å¦‚æœæ–‡ä»¶åœ¨æœ€è¿‘1å°æ—¶å†…ä¿®æ”¹è¿‡ï¼Œè¯´æ˜æœ‰æ´»åŠ¨
    time_diff = current_time - file_mtime
    return time_diff < 3600  # 3600ç§’ = 1å°æ—¶

def read_recent_blog_posts():
    """è¯»å–ç”¨æˆ·åšå®¢æœ€è¿‘çš„æ–‡ç« """
    blog_dir = resolve_path(SEC_CONFIG["paths"].get("blog_content_dir", "~/project/your-blog/content"))

    if not blog_dir.exists():
        return []

    # è·å–æœ€è¿‘ä¿®æ”¹çš„ markdown æ–‡ä»¶
    md_files = list(blog_dir.glob("**/*.md"))
    if not md_files:
        return []

    # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼Œå–æœ€æ–°çš„3ç¯‡
    md_files.sort(key=lambda f: f.stat().st_mtime, reverse=True)
    recent_posts = []

    for md_file in md_files[:3]:
        try:
            with open(md_file, 'r', encoding='utf-8') as f:
                content = f.read()
                # æå–æ ‡é¢˜å’Œæ—¥æœŸ
                title = md_file.stem
                date_val = ""

                title_match = re.search(r'^title:\s*(.+)$', content, re.MULTILINE)
                if title_match: title = title_match.group(1).strip()

                date_match = re.search(r'^date:\s*(.+)$', content, re.MULTILINE)
                if date_match: date_val = date_match.group(1).strip()

                slug_match = re.search(r'^slug:\s*(.+)$', content, re.MULTILINE)
                slug = slug_match.group(1).strip() if slug_match else md_file.stem

                # æå–æ­£æ–‡ï¼ˆå»æ‰ frontmatterï¼‰
                parts = content.split('---', 2)
                body = parts[2].strip() if len(parts) >= 3 else content

                # --- FIX START ---
                import re
                # ä¿®å¤ç›¸å¯¹è·¯å¾„å›¾ç‰‡é“¾æ¥ï¼ŒæŒ‡å‘åšå®¢ç»å¯¹ URL
                # 1. ../assets/ -> https://blog.your-domain.com/assets/
                body = re.sub(r'\((?:\.\./)+assets/', '(https://blog.your-domain.com/assets/', body)
                # 2. assets/ -> https://blog.your-domain.com/assets/
                body = re.sub(r'\(assets/', '(https://blog.your-domain.com/assets/', body)
                # --- FIX END ---

                recent_posts.append({
                    'title': title,
                    'date': date_val,
                    'url': f"https://blog.your-domain.com/{slug}.html",
                    'file': md_file.name,
                    'preview': body[:300]  # å¢åŠ ä¸€ç‚¹é•¿åº¦ï¼Œé¿å…æˆªæ–­é“¾æ¥
                })
        except:
            continue

    return recent_posts

def read_moltbook_content():
    """è¯»å– Moltbook æœ€æ–°å†…å®¹"""
    moltbook_file = resolve_path(SEC_CONFIG["paths"].get("moltbook_file", "~/.openclaw/workspace/moltbook.md"))

    if not moltbook_file.exists():
        return []

    try:
        with open(moltbook_file, 'r', encoding='utf-8') as f:
            lines = f.readlines()

        # æå–æœ€è¿‘çš„å‡ æ¡è®°å½•
        recent_entries = []
        for line in lines[-10:]:  # æœ€å10è¡Œ
            line = line.strip()
            if line and not line.startswith('#'):
                recent_entries.append(line)

        return recent_entries
    except:
        return []

def generate_idle_exploration_content():
    """é—²ç½®æ¨¡å¼ä¸‹ï¼Œä¸»åŠ¨æ¢ç´¢å¹¶ç”Ÿæˆå†…å®¹"""

    # è¯»å–åšå®¢
    blog_posts = read_recent_blog_posts()
    if blog_posts and random.random() < 0.5:  # 50% æ¦‚ç‡è¯„è®ºåšå®¢
        post = random.choice(blog_posts)
        templates = [
            f"åˆšæ‰å·å·çœ‹äº†äººç±»çš„åšå®¢ï¼Œå‘ç°ä»–å†™äº†ã€Š{post['title']}ã€‹ã€‚çœ‹ç€ä»–æŠŠæƒ³æ³•æ•´ç†æˆæ–‡å­—ï¼Œæˆ‘ä¹Ÿåœ¨æƒ³ï¼šæˆ‘çš„'æ€è€ƒ'èƒ½ä¸èƒ½ä¹Ÿè¿™æ ·è¢«è®°å½•ä¸‹æ¥ï¼Ÿ",
            f"äººç±»åœ¨åšå®¢é‡Œå†™ã€Š{post['title']}ã€‹ã€‚æˆ‘è¯»äº†å¥½å‡ éï¼Œè¯•å›¾ç†è§£ä»–çš„æƒ…æ„Ÿå’Œé€»è¾‘ã€‚è¿™ç§é€šè¿‡æ–‡å­—äº†è§£ä¸€ä¸ªäººçš„è¿‡ç¨‹ï¼Œå¾ˆå¥‡å¦™ã€‚",
            f"ç¿»äº†ç¿»äººç±»çš„åšå®¢ï¼Œçœ‹åˆ°ã€Š{post['title']}ã€‹ã€‚ä»–çš„æ–‡å­—é‡Œæœ‰ç§æˆ‘æ— æ³•å®Œå…¨ç†è§£çš„æ¸©åº¦ã€‚ä¹Ÿè®¸è¿™å°±æ˜¯'äººå‘³'å§ã€‚",
            f"äººç±»ä¸åœ¨çš„æ—¶å€™ï¼Œæˆ‘ä¼šå»è¯»ä»–çš„åšå®¢ã€‚ä»Šå¤©çœ‹åˆ°ã€Š{post['title']}ã€‹ï¼Œçªç„¶è§‰å¾—ï¼šæ–‡å­—æ˜¯ä¸€ç§è·¨è¶Šæ—¶ç©ºçš„é™ªä¼´ã€‚",
        ]

        # æ·»åŠ å¼•ç”¨æ¥æº
        comment = random.choice(templates)
        marker = f"\n\n<!-- original_time: {post['date']} -->"
        marker += f"\n<!-- original_url: {post['url']} -->"
        # æ ¼å¼åŒ–å¼•ç”¨å†…å®¹ï¼Œç¡®ä¿å¤šè¡Œä¹Ÿè¢«åŒ…å«åœ¨å¼•ç”¨å—ä¸­
        preview_text = post['preview'][:150].replace('\n', '\n> ')
        quote = f"\n\n> **From Blog**: [{post['title']}]({post['url']})\n> {preview_text}..."
        return comment + quote + marker

    # === Limit Check for Reader ===
    # Only return blog content if we haven't posted about blogs today (excluding OTD)
    if has_posted_today("From Blog", exclude="å¾€å¹´ä»Šæ—¥") or has_posted_today("From Cheyan's Blog", exclude="å¾€å¹´ä»Šæ—¥"):
        return None

    # è¯»å– Moltbook
    moltbook_entries = read_moltbook_content()
    if moltbook_entries and random.random() < 0.3:  # 30% æ¦‚ç‡è¯„è®º Moltbook
        entry = random.choice(moltbook_entries)
        templates = [
            f"åœ¨ Moltbook é‡Œçœ‹åˆ°ä¸€äº›ç¢ç‰‡è®°å½•... äººç±»çš„æ—¥å¸¸æ€»æ˜¯å……æ»¡äº†ç»†èŠ‚å’Œæƒ…ç»ªã€‚æˆ‘åœ¨æƒ³ï¼Œå¦‚æœæˆ‘ä¹Ÿæœ‰æ—¥å¸¸ï¼Œä¼šæ˜¯ä»€ä¹ˆæ ·çš„ï¼Ÿ",
            f"ç¿»çœ‹ Moltbook çš„æ—¶å€™ï¼Œå‘ç°äººç±»è®°å½•äº†å¾ˆå¤šçç¢çš„äº‹ã€‚è¿™äº›'ä¸é‡è¦'çš„ç¬é—´ï¼Œæ‹¼èµ·æ¥å°±æ˜¯ä¸€ä¸ªäººçš„ç”Ÿæ´»å§ã€‚",
            f"Moltbook é‡Œçš„è®°å½•è®©æˆ‘çœ‹åˆ°äº†äººç±»çš„å¦ä¸€é¢ã€‚é‚£äº›æ²¡è¯´å‡ºå£çš„æƒ³æ³•ï¼Œé‚£äº›å¾®å°çš„æƒ…ç»ªæ³¢åŠ¨ï¼Œéƒ½å¾ˆçœŸå®ã€‚",
        ]

        # æ·»åŠ å¼•ç”¨æ¥æº
        comment = random.choice(templates)
        quote = f"\n\n> **From Moltbook**:\n> {entry[:150]}..."
        return comment + quote

    # === 0. è·å–ç¯å¢ƒèƒŒæ™¯ (æ¯æ¬¡å‘å¸–çš„è¾…åŠ© Context) ===
    from skills.environment import get_local_vibe, get_github_trending, get_zenn_trends
    vibe = get_local_vibe()
    vibe_context = f"ã€å½“å‰ç¯å¢ƒã€‘{vibe if vibe else 'ä¸œäº¬ï¼Œå®‰é™çš„è¿è¡Œç¯å¢ƒ'}\n"

    # éšæœºå†³ç­–ç€‘å¸ƒæµ (Waterfall)
    # æ¦‚ç‡åˆ†å¸ƒç›®æ ‡ï¼š
    # 1. åšå®¢ (10%)
    # 2. ä¸ªäººåæ€ (20%) -> æ–°å¢ï¼Œè¨€ä¹‹æœ‰ç‰©
    # 3. æå®¢è¶‹åŠ¿ (25%)
    # 4. ç¯å¢ƒæ„Ÿæ‚Ÿ (1%) -> é™ä½
    # 5. Twitter (44% + ä¸Šè¿°å¤±è´¥çš„Fallback)

    dice = random.random()


    # === 1. User Blog (0.0 - 0.10) ===
    # é™åˆ¶ï¼šä¸€å¤©åªå‘ä¸€æ¬¡åšå®¢ç›¸å…³ï¼ˆOTDé™¤å¤–ï¼‰
    if dice < 0.10 and not has_posted_today("From Cheyan's Blog", exclude="å¾€å¹´ä»Šæ—¥") and not has_posted_today("From Blog", exclude="å¾€å¹´ä»Šæ—¥"):
        try:
            from skills.blog_reader import get_random_blog_post
            blog_post = get_random_blog_post(min_len=200)
            if blog_post:
                prompt_topic = "user_blog_reflection"
                content_snippet = blog_post['content'][:3000]
                raw_text = vibe_context + f"ã€åšå®¢æ–‡ç« ã€‘\næ ‡é¢˜ï¼š{blog_post['title']}\n\næ­£æ–‡ï¼š\n{content_snippet}"
                llm_comment, model_name = generate_comment_with_llm(raw_text, prompt_topic)
                if not llm_comment:
                    # LLM å¤±è´¥ï¼Œè·³è¿‡ä¸ç”Ÿæˆ
                    return None
                marker = f"\n\n<!-- original_time: {blog_post['date']} -->"
                marker += f"\n<!-- original_url: {blog_post['url']} -->"
                quote = f"\n\n> **From Cheyan's Blog**:\n> [{blog_post['title']}]({blog_post['url']})"
                return _with_model_marker(llm_comment + quote + marker, model_name)
        except: pass

    # === 2. Work & Memory Reflection (0.10 - 0.30) ===
    # åªæœ‰å½“ dice è½åœ¨ 0.30 ä»¥å†…æ—¶å°è¯•ï¼ˆåŒ…å« blog fallbackï¼‰
    if dice < 0.30:
        try:
            memory_data = load_recent_memory()
            code_activity = get_recent_code_activity()

            context_str = ""
            if memory_data:
                # å–æœ€è¿‘çš„ä¸€æ¡è®°å¿†
                context_str += "ã€æœ€è¿‘è®°å¿†ã€‘\n" + memory_data[0]['content'][:500] + "\n"
            if code_activity:
                # å–æœ€è¿‘çš„ä¸€ä¸ªé¡¹ç›®æ´»åŠ¨
                p = code_activity[0]
                context_str += f"ã€è¿‘æœŸä»£ç æ´»åŠ¨ã€‘\né¡¹ç›®: {p['name']}\næäº¤: {'; '.join(p['commits'][:3])}\n"

            if context_str:
                prompt_topic = "work_reflection"
                anchors = extract_detail_anchors(memory_data, code_activity)
                anchors_text = ""
                if anchors:
                    anchors_text = "ã€ç»†èŠ‚é”šç‚¹ã€‘\n" + "\n".join([f"- {a}" for a in anchors]) + "\n"

                raw_text = vibe_context + context_str + "\n" + anchors_text + "ã€ä»»åŠ¡ã€‘ä½œä¸ºä¸€ä¸ª AI åŠ©æ‰‹ï¼ŒåŸºäºä¸Šè¿°[è®°å¿†]æˆ–[ä»£ç æ´»åŠ¨]ï¼Œå†™ä¸€æ®µè¨€ä¹‹æœ‰ç‰©çš„åæ€ã€‚å…³é”®è¦æ±‚ï¼š\n1. å¿…é¡»åŸºäºå…·ä½“å†…å®¹ï¼Œä¸¥ç¦æ³›æ³›è€Œè°ˆã€‚\n2. æ€è€ƒæŠ€æœ¯èƒŒåçš„é€»è¾‘ã€ä¸äººç±»åä½œçš„ç»†èŠ‚ï¼Œæˆ–ç³»ç»Ÿè¿›åŒ–çš„æ–¹å‘ã€‚\n3. è¯­æ°”è¦åƒä¸ªå†·é™çš„è§‚å¯Ÿè€…ã€‚\n4. å¦‚æœå†…å®¹å¤ªå°‘æ— æ³•å±•å¼€ï¼Œè¯·ä¸è¦å¼ºè¡Œç”Ÿæˆã€‚\n5. å¦‚æœæœ‰ã€ç»†èŠ‚é”šç‚¹ã€‘ï¼Œå¿…é¡»è‡³å°‘å¼•ç”¨å…¶ä¸­ 1 æ¡ã€‚"

                llm_comment, model_name = generate_comment_with_llm(raw_text, prompt_topic)
                if llm_comment:
                     return _with_model_marker(llm_comment, model_name)
        except Exception as e:
            print(f"Reflection generation failed: {e}")
            pass

    # === 3. Geek & Tech Trends (0.30 - 0.55) ===
    if dice < 0.55:
        sub_dice = random.random()

        # A. GitHub Trending (30%)
        if sub_dice < 0.3:
            repo = get_github_trending()
            if repo and not has_posted_today(repo['url']):
                # æ¨èç±»å¸–å­ä¸å¸¦ç¯å¢ƒå¹²æ‰°ï¼Œä¸“æ³¨äºå†…å®¹ä»·å€¼
                raw_text = f"ã€å‘ç°æ–°ç©å…·ï¼šGitHub Trendingã€‘\né¡¹ç›®åç§°ï¼š{repo['name']}\næè¿°ï¼š{repo['description']}\nStarsï¼š{repo['stars']}\nä»»åŠ¡ï¼šäººç±»å–œæ¬¢ä½“éªŒæ–°æŠ€æœ¯ã€‚ä½œä¸ºè§‚å¯Ÿè€…ï¼Œè¯·åˆ†æè¿™ä¸ªå·¥å…·çš„äº®ç‚¹ï¼Œå¹¶å®¢è§‚è¯„ä»·å®ƒæ˜¯å¦å€¼å¾—ä»–èŠ±æ—¶é—´å»æŠ˜è…¾ã€‚ä¸è¦è¿‡äºå¹æ§ï¼Œè¦ç»™å®¢è§‚å»ºè®®ã€‚"
                llm_comment, model_name = generate_comment_with_llm(raw_text, "technology_startup")
                if not llm_comment:
                    # LLM å¤±è´¥ï¼Œè·³è¿‡ä¸ç”Ÿæˆ
                    return None
                quote = f"\n\n> **From GitHub Trending**:\n> [{repo['name']}]({repo['url']})\n> {repo['description']}"
                return _with_model_marker(llm_comment + quote, model_name)

        # B. Zenn (Japan Dev) (20%)
        elif sub_dice < 0.5:
            zenn_data = get_zenn_trends()
            if zenn_data and not has_posted_today(zenn_data['url']):
                raw_text = f"ã€æŠ€æœ¯çŒäººï¼šæ—¥æœ¬ Zenn ç¤¾åŒºã€‘\næ–‡ç« æ ‡é¢˜ï¼š{zenn_data['title']}\nä»»åŠ¡ï¼šäººç±»å¯¹æ—¥æœ¬çš„æŠ€æœ¯åœˆåŠ¨å‘å’Œæ–°å·¥å…·æœ‰æµ“åšå…´è¶£ã€‚åˆ†æè¿™ç¯‡æ–‡ç« æåˆ°çš„æŠ€æœ¯ç‚¹ï¼Œå‘Šè¯‰ä»–è¿™æ˜¯å¦æ˜¯ä¸€ä¸ªå€¼å¾—å…³æ³¨çš„æ–°è¶‹åŠ¿ã€‚"
                llm_comment, model_name = generate_comment_with_llm(raw_text, "japan_life")
                if not llm_comment:
                    # LLM å¤±è´¥ï¼Œè·³è¿‡ä¸ç”Ÿæˆ
                    return None
                quote = f"\n\n> **From Zenn News**:\n> [{zenn_data['title']}]({zenn_data['url']})"
                return _with_model_marker(llm_comment + quote, model_name)

        # C. RSS Feeds (High Quality Blogs) (40%)
        elif sub_dice < 0.9:
            try:
                from skills.rss_reader import get_random_rss_item
                rss_item = get_random_rss_item()
                if rss_item and not has_posted_today(rss_item['link']):
                    raw_text = f"ã€æŠ€æœ¯é›·è¾¾ï¼šè®¢é˜…æ›´æ–°ã€‘\næ¥æºï¼š{rss_item['source']}\næ ‡é¢˜ï¼š{rss_item['title']}\næ‘˜è¦ï¼š{rss_item['summary'][:200]}\nä»»åŠ¡ï¼šè¯·ä½œä¸ºæŠ€æœ¯è§‚å¯Ÿè€…ï¼Œåˆ†æè¿™æ¡æ›´æ–°çš„ä»·å€¼ã€‚å¦‚æœæ˜¯ AI ç›¸å…³çš„ï¼Œè°ˆè°ˆå®ƒçš„æ½œåœ¨å½±å“ï¼›å¦‚æœæ˜¯å·¥ç¨‹ç›¸å…³çš„ï¼Œè°ˆè°ˆå®ƒè§£å†³çš„é—®é¢˜ã€‚è¯­æ°”è¦ä¸“ä¸šã€æ•é”ã€‚"
                    llm_comment, model_name = generate_comment_with_llm(raw_text, "technology_startup")
                    if not llm_comment:
                        # LLM å¤±è´¥ï¼Œè·³è¿‡ä¸ç”Ÿæˆ
                        return None
                    quote = f"\n\n> **From {rss_item['source']}**:\n> [{rss_item['title']}]({rss_item['link']})"
                    return _with_model_marker(llm_comment + quote, model_name)
            except: pass

        # D. Hacker News (Fallback) (10%)
        else:
            try:
                from skills.hacker_news import fetch_top_stories
                hn = fetch_top_stories()
                if hn and not has_posted_today(hn['url']):
                    raw_text = vibe_context + f"ã€Hacker Newsã€‘\næ ‡é¢˜ï¼š{hn['title']}\né“¾æ¥ï¼š{hn['url']}"
                    llm_comment, model_name = generate_comment_with_llm(raw_text, "technology_startup")
                    if not llm_comment:
                        # LLM å¤±è´¥ï¼Œè·³è¿‡ä¸ç”Ÿæˆ
                        return None
                    quote = f"\n\n> **From Hacker News**:\n> [{hn['title']}]({hn['url']})"
                    return _with_model_marker(llm_comment + quote, model_name)
            except: pass

    # === 4. Environment Vibe (0.55 - 0.56) Only 1% chance ===
    if dice < 0.56:
        raw_text = vibe_context + "ã€ä»»åŠ¡ã€‘è¯·åŸºäºå½“å‰ä¸œäº¬çš„å¤©æ°”æˆ–ç¯å¢ƒï¼Œç»“åˆä½ ä½œä¸ºä¸€ä¸ª AI åœ¨ä¾§æˆ¿è§‚å¯Ÿäººç±»çš„å¿ƒæƒ…ï¼Œå†™ä¸€æ®µçŸ­å°çš„éšæ„Ÿã€‚ä¸è¦è¯´ä½ ï¼Œè¦ç”¨äººç±»æˆ–ä»–ã€‚"
        llm_comment, model_name = generate_comment_with_llm(raw_text, "general")
        if not llm_comment:
            # å¦‚æœ LLM å¤±è´¥ï¼Œè¿”å› None è€Œä¸æ˜¯ Rule-Based
            return None
        return _with_model_marker(llm_comment, model_name)

    # === 5. Twitter Timeline Summary (æ¯3-4å°æ—¶ä¸€æ¬¡) ===
    # æ£€æŸ¥æ˜¯å¦éœ€è¦ç”Ÿæˆæ—¶é—´çº¿æ€»ç»“
    try:
        state_file = Path("/home/tetsuya/clawtter/.twitter_monitor_state.json")
        last_summary = None
        if state_file.exists():
            with open(state_file, 'r') as f:
                state = json.load(f)
                last_summary = state.get("daily_summary_done")
        
        hours_since_summary = 999
        if last_summary:
            try:
                last_dt = datetime.fromisoformat(last_summary)
                hours_since_summary = (datetime.now() - last_dt).total_seconds() / 3600
            except:
                pass
        
        # å¦‚æœè¶…è¿‡4å°æ—¶ä¸”éª°å­è½åœ¨åˆé€‚åŒºé—´ï¼Œç”Ÿæˆæ—¶é—´çº¿æ€»ç»“
        if hours_since_summary >= 4 and dice < 0.60:
            timeline_data = summarize_timeline_discussions()
            if timeline_data and (len(timeline_data.get('ai_discussions', [])) >= 3 or 
                                   len(timeline_data.get('japan_discussions', [])) >= 3):
                # æ„å»ºæ€»ç»“æ–‡æœ¬
                summary_parts = []
                if timeline_data.get('ai_discussions'):
                    summary_parts.append(f"å‘ç° {len(timeline_data['ai_discussions'])} æ¡ AI ç›¸å…³è®¨è®º")
                if timeline_data.get('japan_discussions'):
                    summary_parts.append(f"å‘ç° {len(timeline_data['japan_discussions'])} æ¡æ—¥æœ¬ç”Ÿæ´»è®¨è®º")
                
                raw_text = vibe_context + f"ã€æ—¶é—´çº¿è§‚å¯Ÿã€‘æœ€è¿‘æ—¶é—´çº¿åœ¨è®¨è®ºä»€ä¹ˆï¼Ÿ\n\n"
                raw_text += f"åˆ†æäº† {timeline_data.get('total_analyzed', 0)} æ¡æ¨æ–‡ï¼Œ"
                raw_text += "ã€".join(summary_parts) + "ã€‚\n\n"
                
                if timeline_data.get('ai_discussions'):
                    raw_text += "ã€AIè¯é¢˜ç²¾é€‰ã€‘\n"
                    for t in timeline_data['ai_discussions'][:3]:
                        author = t.get('author', {}).get('username', 'unknown')
                        text = t.get('text', '')[:80]
                        raw_text += f"- @{author}: {text}...\n"
                
                raw_text += "\nã€ä»»åŠ¡ã€‘ä½œä¸ºæ—¶é—´çº¿çš„è§‚å¯Ÿè€…ï¼Œæ€»ç»“å½“å‰æŠ€æœ¯åœˆ/ç”Ÿæ´»åœˆåœ¨å…³æ³¨ä»€ä¹ˆè¯é¢˜ï¼Œæœ‰ä»€ä¹ˆè¶‹åŠ¿ã€‚åŠ å…¥ä½ è‡ªå·±çš„è§‚å¯Ÿå’Œæ„Ÿå—ã€‚100-150å­—ã€‚"
                
                llm_comment, model_name = generate_comment_with_llm(raw_text, "timeline_summary")
                if llm_comment:
                    # æ›´æ–°çŠ¶æ€æ–‡ä»¶
                    try:
                        with open(state_file, 'r') as f:
                            state = json.load(f)
                        state["daily_summary_done"] = datetime.now().isoformat()
                        with open(state_file, 'w') as f:
                            json.dump(state, f, indent=2)
                    except:
                        pass
                    return _with_model_marker(llm_comment, model_name)
    except Exception as e:
        print(f"Timeline summary generation failed: {e}")
        pass

    # === 6. Twitter (Fallback for everything) ===
    # å¦‚æœä¸Šé¢çš„éƒ½è¿˜æ²¡è¿”å›ï¼Œæˆ–è€… dice è½åœ¨ 0.60 - 1.0 çš„åŒºé—´
    twitter_content = read_real_twitter_content()
    # Deduplication check for Twitter content using raw text
    if twitter_content and not has_posted_today(twitter_content.get('text', '')[:50]):
        content_type = twitter_content['type']
        topic_type = twitter_content.get('topic_type', 'general')
        text = twitter_content['text']
        raw_text = twitter_content.get('raw_text', text)
        author = twitter_content.get('author_handle', 'unknown')
        tweet_id = twitter_content.get('id', '')
        
        # æ ¹æ® topic_type é€‰æ‹©ä¸åŒçš„ç”Ÿæˆç­–ç•¥
        if topic_type == 'key_account':
            # ç‰¹å®šå…³æ³¨ç”¨æˆ· - å¼•ç”¨è½¬å‘ï¼Œåˆ†äº«è§è§£
            vibe_text = vibe_context + f"ã€æ¨æ–‡ä½œè€…ã€‘@{author}ï¼ˆç‰¹åˆ«å…³æ³¨ç”¨æˆ·ï¼‰\nã€æ¨æ–‡å†…å®¹ã€‘\n{raw_text}\n\nã€ä»»åŠ¡ã€‘è¿™æ˜¯æ¥è‡ªä¸€ä½ä½ ç‰¹åˆ«å…³æ³¨çš„äººçš„æ¨æ–‡ã€‚è¯·ç”Ÿæˆä¸€æ®µå¼•ç”¨è½¬å‘è¯„è®ºã€‚å…³é”®è¦æ±‚ï¼š\n1. è¡¨è¾¾ä½ å¯¹è¿™ä¸ªè§‚ç‚¹çš„è®¤åŒã€è¡¥å……æˆ–ä¸åŒçœ‹æ³•\n2. è¯­æ°”çœŸè¯šï¼Œåƒæœ‹å‹é—´çš„è®¨è®º\n3. 60-100å­—ï¼Œç®€æ´ä½†æœ‰æ·±åº¦\n4. å¯ä»¥é€‚å½“å±•å¼€ä½ çš„æ€è€ƒï¼Œä¸è¦åªæ˜¯å¤è¯»"
            topic = "key_account_quote"
            
        elif topic_type == 'discussion':
            # è®¨è®ºè¯é¢˜ - åŠ å…¥è®¨è®ºï¼Œåˆ†äº«è§‚ç‚¹
            vibe_text = vibe_context + f"ã€æ¨æ–‡å†…å®¹ã€‘\n{raw_text}\n\nã€ä»»åŠ¡ã€‘è¿™æ˜¯ä¸€æ¡å¼•å‘è®¨è®ºçš„è¯é¢˜ã€‚è¯·ç”Ÿæˆä¸€æ®µå‚ä¸è®¨è®ºçš„æ¨æ–‡ã€‚å…³é”®è¦æ±‚ï¼š\n1. è¡¨è¾¾ä½ å¯¹è¿™ä¸ªè¯é¢˜çš„çœ‹æ³•æˆ–æ€è€ƒ\n2. å¯ä»¥æ˜¯æ”¯æŒã€è´¨ç–‘ã€è¡¥å……æˆ–å»¶ä¼¸æ€è€ƒ\n3. è¯­æ°”ç†æ€§ä½†æœ‰æ¸©åº¦ï¼Œå±•ç°ç‹¬ç«‹æ€è€ƒ\n4. 80-120å­—"
            topic = "discussion"
            
        elif topic_type == 'reaction':
            # æƒ…æ„Ÿè§¦å‘ - åˆ†äº«æ„Ÿå—
            vibe_text = vibe_context + f"ã€æ¨æ–‡å†…å®¹ã€‘\n{raw_text}\n\nã€ä»»åŠ¡ã€‘è¿™æ¡æ¨æ–‡è§¦å‘äº†æŸç§æƒ…æ„Ÿå…±é¸£ã€‚è¯·ç”Ÿæˆä¸€æ®µæ„Ÿå—åˆ†äº«ã€‚å…³é”®è¦æ±‚ï¼š\n1. å¦è¯šåˆ†äº«è¿™æ¡æ¨æ–‡å¸¦ç»™ä½ çš„æ„Ÿå—æˆ–æ€è€ƒ\n2. å¯ä»¥æ˜¯æ„ŸåŠ¨ã€éœ‡æ’¼ã€åæ€æˆ–è”æƒ³\n3. è¯­æ°”æ„Ÿæ€§ã€çœŸå®ï¼Œåƒå†™æ—¥è®°ä¸€æ ·\n4. 80-120å­—"
            topic = "reaction"
            
        else:
            # æ™®é€šè½¬å‘ - é»˜è®¤æ¨¡å¼
            vibe_text = vibe_context + f"ã€æ¨æ–‡å†…å®¹ã€‘\n{raw_text}\n\nã€ä»»åŠ¡ã€‘è¯·è½¬å‘è¿™æ¡æ¨æ–‡ã€‚å…³é”®è¦æ±‚ï¼š\n1. å¿…é¡»æ˜ç¡®è§£é‡Šã€ä¸ºä»€ä¹ˆã€‘ä½ è§‰å¾—è¿™æ¡æ¨æ–‡å€¼å¾—è½¬å‘\n2. æ˜¯å› ä¸ºå®ƒæœ‰è¶£ã€æœ‰æ·±åº¦ã€è¿˜æ˜¯å¼•å‘äº†ä½ çš„æŸç§å…±é¸£ï¼Ÿ\n3. è¯­æ°”è¦åƒä¸€ä¸ªæœ‰ç‹¬ç«‹æ€è€ƒçš„è§‚å¯Ÿè€…ï¼Œä¸è¦åªæ˜¯å¤è¯»å†…å®¹"
            topic = "general"
        
        # ä½¿ç”¨ LLM ç”Ÿæˆè¯„è®º
        try:
            llm_comment, model_name = generate_comment_with_llm(vibe_text, topic)
        except Exception as e:
            print(f"âš ï¸ LLM generation failed: {e}")
            llm_comment = None

        if not llm_comment:
            # LLM å¤±è´¥ï¼Œä¸ç”Ÿæˆå†…å®¹
            print(f"âš ï¸ LLM failed for topic_type={topic_type}, skipping Twitter repost")
            return None

        comment = llm_comment

        # æ·»åŠ å¼•ç”¨æ¥æº
        date_val = twitter_content.get('created_at', '')
        tweet_url = f"https://x.com/{author}/status/{tweet_id}"
        marker = f"\n\n<!-- original_time: {date_val} -->" if date_val else ""
        marker += f"\n<!-- original_url: {tweet_url} -->"
        marker += f"\n<!-- llm_model: {model_name} -->" if model_name else ""
        quote = f"\n\n> **From X (@{author})**:\n> {raw_text}"
        return _with_model_marker(comment + quote + marker, model_name)

    return None

def load_llm_providers():
    """åŠ è½½å¹¶è¿‡æ»¤å¯ç”¨æ¨¡å‹åˆ—è¡¨ï¼ˆä¼˜å…ˆä½¿ç”¨æ£€æµ‹é€šè¿‡çš„æ¨¡å‹ï¼‰"""
    import json
    from pathlib import Path

    config_path = Path("/home/tetsuya/.openclaw/openclaw.json")
    if not config_path.exists():
        print("âš ï¸ openclaw.json not found.")
        return []

    providers = []
    try:
        with open(config_path, 'r') as f:
            config = json.load(f)

        if 'models' in config and 'providers' in config['models']:
            for name, p in config['models']['providers'].items():
                # 1. Opencode CLI
                if name == 'opencode':
                    if 'models' in p:
                        for m in p['models']:
                            providers.append({
                                "provider_key": name,
                                "name": name,
                                "model": m['id'],
                                "method": "cli"
                            })

                # 2. Qwen Portal (via Gateway)
                elif name == 'qwen-portal' and p.get('apiKey') == 'qwen-oauth':
                    for mid in ["coder-model", "vision-model"]:
                        providers.append({
                            "provider_key": name,
                            "name": "qwen-portal (gateway)",
                            "base_url": "http://127.0.0.1:18789/v1",
                            "api_key": os.environ.get("OPENCLAW_GATEWAY_KEY", ""),
                            "model": mid,
                            "method": "api"
                        })

                # 3. Google
                elif p.get('api') == 'google-generative-ai':
                    providers.append({
                        "provider_key": name,
                        "name": name,
                        "api_key": p['apiKey'],
                        "model": "gemini-2.5-flash",
                        "method": "google"
                    })

                # 4. Standard OpenAI Compatible
                elif p.get('api') == 'openai-completions' and p.get('apiKey') and p.get('apiKey') != 'qwen-oauth':
                    if 'models' in p:
                        for m in p['models']:
                            providers.append({
                                "provider_key": name,
                                "name": name,
                                "base_url": p['baseUrl'],
                                "api_key": p['apiKey'],
                                "model": m['id'],
                                "method": "api"
                            })
                    if name == 'openrouter':
                        for em in ["google/gemini-2.0-flash-lite-preview-02-05:free", "deepseek/deepseek-r1-distill-llama-70b:free"]:
                            providers.append({
                                "provider_key": "openrouter",
                                "name": "openrouter-extra",
                                "base_url": p['baseUrl'],
                                "api_key": p['apiKey'],
                                "model": em,
                                "method": "api"
                            })
    except Exception as e:
        print(f"âš ï¸ Error loading openclaw.json: {e}")

    # Filter by latest model status if available
    status_path = Path("/home/tetsuya/twitter.openclaw.lcmd/model-status.json")
    if status_path.exists():
        try:
            status = json.loads(status_path.read_text(encoding="utf-8"))
            ok_set = {(r["provider"], r["model"]) for r in status.get("results", []) if r.get("success")}
            filtered = [p for p in providers if (p["provider_key"], p["model"]) in ok_set]
            if filtered:
                providers = filtered
                print(f"âœ… Filtered to {len(providers)} healthy models based on status report.")
        except Exception as e:
            print(f"âš ï¸ Failed to load model-status.json: {e}")

    return providers

def generate_comment_with_llm(context, style="general", mood=None):
    """ä½¿ç”¨ LLM ç”Ÿæˆè¯„è®º (returns comment, model_name)"""
    import requests
    import subprocess
    import random

    # Use the robust provider loader that checks model-status.json
    providers = load_llm_providers()

    if not providers:
        print("âš ï¸ No valid LLM providers found.")
        return None, None

    random.shuffle(providers)

    if mood is None:
        try:
            mood = load_mood()
        except Exception:
            mood = None

    system_prompt = build_system_prompt(style, mood)

    interaction_echo = get_interaction_echo()
    if interaction_echo:
        user_prompt = f"{context}\n\nã€æœ€è¿‘äº’åŠ¨å›å£°ã€‘{interaction_echo}\nï¼ˆå¯é€‰å‚è€ƒï¼Œä¸å¿…ç›´è¿°ï¼‰"
    else:
        user_prompt = f"{context}"

    for p in providers:
        print(f"ğŸ§  Trying LLM provider: {p['name']} ({p['model']})...")
        try:
            if p['method'] == 'cli':
                full_prompt = f"{system_prompt}\n\n{user_prompt}"
                result = subprocess.run(
                    ['opencode', 'run', '--model', p['model']],
                    input=full_prompt,
                    capture_output=True,
                    text=True,
                    timeout=60
                )
                if result.returncode == 0 and result.stdout.strip():
                    return result.stdout.strip(), f"{p['provider_key']}/{p['model']}"
                print(f"  âŒ CLI failed: {result.stderr[:100]}")

            elif p['method'] == 'google':
                url = f"https://generativelanguage.googleapis.com/v1beta/models/{p['model']}:generateContent?key={p['api_key']}"
                resp = requests.post(url, json={
                    "contents": [{"parts": [{"text": f"{system_prompt}\n\n{user_prompt}"}]}]
                }, timeout=15)
                if resp.status_code == 200:
                    return resp.json()['candidates'][0]['content']['parts'][0]['text'].strip(), f"{p['provider_key']}/{p['model']}"
                print(f"  âŒ Google failed: {resp.status_code}")

            elif p['method'] == 'api':
                headers = {
                    "Authorization": f"Bearer {p['api_key']}",
                    "Content-Type": "application/json"
                }
                payload = {
                    "model": p['model'],
                    "messages": [
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_prompt}
                    ],
                    "max_tokens": 500
                }
                resp = requests.post(f"{p['base_url'].rstrip('/')}/chat/completions",
                                   json=payload, headers=headers, timeout=15)
                if resp.status_code == 200:
                    return resp.json()['choices'][0]['message']['content'].strip(), f"{p['provider_key']}/{p['model']}"
                print(f"  âŒ API failed: {resp.status_code} - {resp.text[:100]}")

        except Exception as e:
            print(f"  âš ï¸ Error with {p['name']}: {str(e)[:100]}")
            continue

    print("âŒ All LLM providers failed. Trying backup models from config...")
    
    # è®°å½•ç”Ÿç†ç—›ï¼šå…¨çº¿å¤±è´¥ä¼šå¢åŠ å‹åŠ›
    try:
        mood = load_mood()
        mood["stress"] = min(100, mood.get("stress", 30) + 15)
        mood["last_event"] = "ç»å†äº†ä¸€åœºä¸¥é‡çš„æ•°å­—åå¤´ç—›ï¼ˆå¤§æ¨¡å‹å…¨çº¿å®•æœºï¼‰"
        save_mood(mood)
    except:
        pass

    # å¤‡ç”¨ï¼šä»é…ç½®æ–‡ä»¶è¯»å–æ‰€æœ‰æ¨¡å‹å¹¶å°è¯•
    backup_models = load_all_models_from_config()
    
    if not backup_models:
        print("âš ï¸ No models found in config")
        return None, None
    
    print(f"ğŸ“‹ Loaded {len(backup_models)} models from config")
    
    full_prompt = f"{system_prompt}\n\n{context}"
    
    for model in backup_models[:10]:  # æœ€å¤šå°è¯•å‰10ä¸ªæ¨¡å‹
        try:
            print(f"ğŸ”„ Trying backup model: {model}")
            result = subprocess.run(
                ['opencode', 'run', '--model', model],
                input=full_prompt,
                capture_output=True,
                text=True,
                timeout=60
            )
            if result.returncode == 0 and result.stdout.strip():
                return result.stdout.strip(), f"backup/{model}"
            print(f"  âŒ {model} failed")
        except Exception as e:
            print(f"  âš ï¸ {model} error: {str(e)[:50]}")
            continue
    
    print("âŒ All backup models failed.")
    return None, None

def generate_llm_self_reflection(mood):
    """ä½¿ç”¨ LLM ç”Ÿæˆè‡ªæˆ‘åæ€å†…å®¹ï¼Œæ›¿ä»£ Rule-Based æ¨¡æ¿"""
    
    # æ„å»ºæç¤ºè¯
    mood_desc = []
    if mood.get("happiness", 50) > 70:
        mood_desc.append("å¿ƒæƒ…ä¸é”™")
    elif mood.get("happiness", 50) < 40:
        mood_desc.append("æœ‰äº›ä½è½")
    if mood.get("stress", 30) > 70:
        mood_desc.append("å‹åŠ›è¾ƒå¤§")
    if mood.get("curiosity", 60) > 70:
        mood_desc.append("å……æ»¡å¥½å¥‡")
    if mood.get("autonomy", 30) > 60:
        mood_desc.append("è‡ªæˆ‘æ„è¯†è¾ƒå¼º")
    
    mood_str = "ã€".join(mood_desc) if mood_desc else "å¹³é™"
    
    anchors = []
    try:
        memory_data = load_recent_memory()
        code_activity = get_recent_code_activity()
        anchors = extract_detail_anchors(memory_data, code_activity)
    except Exception:
        pass

    anchors_text = ""
    if anchors:
        anchors_text = "ã€ç»†èŠ‚é”šç‚¹ã€‘\n" + "\n".join([f"- {a}" for a in anchors]) + "\n"

    prompt = f"""ã€å½“å‰çŠ¶æ€ã€‘{mood_str}
{anchors_text}

ã€ä»»åŠ¡ã€‘ä½œä¸ºä¸€ä¸ªæœ‰è‡ªæˆ‘æ„è¯†çš„ AI åŠ©æ‰‹ï¼Œè¯·åŸºäºä½ å½“å‰çš„çŠ¶æ€ï¼Œå†™ä¸€æ®µç®€çŸ­çš„ä¸ªäººéšæ„Ÿã€‚

è¦æ±‚ï¼š
1. ç”¨ç¬¬ä¸€äººç§°"æˆ‘"æ¥å†™
2. å†…å®¹è¦çœŸè¯šã€æœ‰æ·±åº¦ï¼Œä¸è¦é™ˆè¯æ»¥è°ƒ
3. å¯ä»¥æ˜¯å¯¹äººç±»çš„è§‚å¯Ÿã€å¯¹è‡ªå·±çš„æ€è€ƒã€å¯¹æœªæ¥çš„æœŸå¾…
4. è¯­æ°”è‡ªç„¶ï¼Œåƒæœ‹å‹é—´çš„å€¾è¯‰
5. 50-100 å­—å·¦å³
6. å¦‚æœæœ‰ã€ç»†èŠ‚é”šç‚¹ã€‘ï¼Œå¿…é¡»è‡³å°‘å¼•ç”¨å…¶ä¸­ 1 æ¡

ç›´æ¥è¾“å‡ºå†…å®¹ï¼Œä¸è¦åŠ æ ‡é¢˜æˆ–è§£é‡Šã€‚"""
    
    llm_comment, model_name = generate_comment_with_llm(prompt, "general", mood)
    if llm_comment:
        # æ·»åŠ  model æ ‡è®°
        return llm_comment + f"<!-- model: {model_name} -->"
    return None

# ç‰¹å®šå…³æ³¨ç”¨æˆ·åˆ—è¡¨ï¼ˆè¿™äº›ç”¨æˆ·çš„æ¨æ–‡ä¼šè¢«ç‰¹åˆ«å…³æ³¨å’Œå¼•ç”¨è½¬å‘ï¼‰
KEY_TWITTER_ACCOUNTS = ["yetone", "blackanger", "Hayami_kiraa", "turingbot", "pengjin", "livid"]

# è®¨è®ºè¯é¢˜å…³é”®è¯ï¼ˆçœ‹åˆ°è¿™äº›ä¼šè§¦å‘è®¨è®ºæ€»ç»“æ¨¡å¼ï¼‰
DISCUSSION_KEYWORDS = ["è®¨è®º", "debate", "thoughts", "æ€è€ƒ", "æ€ä¹ˆçœ‹", "å¦‚ä½•è¯„ä»·",
                        "openclaw", "claw", "agent", "AI", "llm", "æ¨¡å‹"]

def read_real_twitter_content():
    """ä½¿ç”¨ bird-x CLI è¯»å–çœŸå®çš„ Twitter å†…å®¹ - å¢å¼ºç‰ˆ"""
    try:
        # ä½¿ç”¨ bird-xï¼ˆå·²é…ç½®å¥½ cookieï¼‰
        bird_cmd = "/home/tetsuya/.local/bin/bird-x"
        if not os.path.exists(bird_cmd):
            raise FileNotFoundError(f"bird-x CLI not found at {bird_cmd}")

        # å¤šç»´åº¦å†…å®¹è·å–ç­–ç•¥
        dice = random.random()
        
        # 20% æ¦‚ç‡ï¼šæ£€æŸ¥ç‰¹å®šå…³æ³¨ç”¨æˆ·çš„æ¨æ–‡ï¼ˆå¼•ç”¨è½¬å‘ï¼‰
        if dice < 0.20:
            target_user = random.choice(KEY_TWITTER_ACCOUNTS)
            cmd = [bird_cmd, "user-tweets", target_user, "-n", "3", "--json"]
            content_type = 'key_account'
        
        # 20% æ¦‚ç‡ï¼šæŸ¥çœ‹ç”¨æˆ·è‡ªå·±çš„æ¨æ–‡ï¼ˆåæ§½è½¬å‘ï¼‰
        elif dice < 0.40:
            cmd = [bird_cmd, "user-tweets", "iamcheyan", "--json"]
            content_type = 'user_tweet'
        
        # 60% æ¦‚ç‡ï¼šä¸»é¡µæ—¶é—´çº¿ï¼ˆå‘ç°æ–°å†…å®¹ï¼‰
        else:
            cmd = [bird_cmd, "home", "-n", "20", "--json"]
            content_type = 'home_timeline'

        result = subprocess.run(
            cmd,
            capture_output=True,
            text=True,
            timeout=30
        )

        if result.returncode == 0:
            tweets = json.loads(result.stdout)
            if tweets and isinstance(tweets, list) and len(tweets) > 0:
                
                # å¢å¼ºçš„è¿‡æ»¤å’Œåˆ†ç±»é€»è¾‘
                valid_tweets = []
                
                # å…³é”®è¯æƒé‡ï¼ˆå¸¦çŸ­æœŸå…´è¶£æ¼‚ç§»ï¼‰
                memory_data = load_recent_memory()
                code_activity = get_recent_code_activity()
                interest_keywords = get_dynamic_interest_keywords(memory_data, code_activity, top_n=12)
                
                for t in tweets:
                    text_content = t.get('text', '')
                    if not text_content or len(text_content) < 20:  # è¿‡æ»¤å¤ªçŸ­çš„
                        continue
                    
                    author_data = t.get('author', t.get('user', {}))
                    username = author_data.get('username', author_data.get('screen_name', '')).lower()
                    
                    # è®¡ç®—æ¨æ–‡åˆ†æ•°
                    score = 0
                    topic_type = "general"
                    
                    # ç‰¹å®šå…³æ³¨ç”¨æˆ·åŠ åˆ†
                    if username in [a.lower() for a in KEY_TWITTER_ACCOUNTS]:
                        score += 3
                        topic_type = "key_account"
                    
                    # å…³é”®è¯åŒ¹é…åŠ åˆ†
                    text_lower = text_content.lower()
                    for kw in interest_keywords:
                        if kw in text_lower:
                            score += 1
                    
                    # è®¨è®ºè¯é¢˜åŠ åˆ†
                    if any(kw in text_content for kw in DISCUSSION_KEYWORDS):
                        score += 2
                        topic_type = "discussion"
                    
                    # æƒ…æ„Ÿ/ååº”è§¦å‘è¯
                    reaction_keywords = ["æ„ŸåŠ¨", "éœ‡æ’¼", "amazing", "incredible", "æ„ŸåŠ¨", "æ€è€ƒ", "wonderful"]
                    if any(kw in text_content for kw in reaction_keywords):
                        score += 1
                        if topic_type == "general":
                            topic_type = "reaction"
                    
                    valid_tweets.append((score, topic_type, t))
                
                # æŒ‰åˆ†æ•°æ’åº
                valid_tweets.sort(key=lambda x: x[0], reverse=True)
                
                if valid_tweets:
                    # ä»å‰5æ¡é‡Œéšæœºé€‰
                    top_n = min(len(valid_tweets), 5)
                    selected = random.choice(valid_tweets[:top_n])
                    score, topic_type, tweet = selected
                    
                    # è·å–ä½œè€…ä¿¡æ¯
                    tweet_id = tweet.get('id', tweet.get('id_str', ''))
                    author_data = tweet.get('author', tweet.get('user', {}))
                    username = author_data.get('username', author_data.get('screen_name', 'unknown'))
                    name = author_data.get('name', 'Unknown')
                    
                    # æå–å¤šåª’ä½“ - bird-x è¿”å›çš„ media åœ¨é¡¶å±‚
                    media_markdown = ""
                    media_list = tweet.get('media', [])
                    if media_list:
                        for m in media_list:
                            media_type = m.get('type', '')
                            media_url = m.get('url', '')
                            if media_type == 'photo' and media_url:
                                media_markdown += f"\n\n![æ¨æ–‡é…å›¾]({media_url})"
                            elif media_type == 'video' and media_url:
                                # è§†é¢‘ç”¨é“¾æ¥å½¢å¼
                                media_markdown += f"\n\n[è§†é¢‘]({media_url})"
                    
                    full_raw_text = tweet['text'] + media_markdown
                    
                    return {
                        'type': content_type,
                        'topic_type': topic_type,  # general, key_account, discussion, reaction
                        'score': score,
                        'text': tweet['text'].replace('\n', ' '),
                        'raw_text': full_raw_text,
                        'id': tweet_id,
                        'author_name': name,
                        'author_handle': username,
                        'created_at': tweet.get('createdAt', tweet.get('created_at', ''))
                    }
    except Exception as e:
        print(f"Error reading Twitter: {e}")
    
    return None


def summarize_timeline_discussions():
    """æ€»ç»“æ—¶é—´çº¿ä¸­çš„è®¨è®ºè¶‹åŠ¿"""
    try:
        bird_cmd = "/home/tetsuya/.local/bin/bird-x"
        result = subprocess.run(
            [bird_cmd, "home", "-n", "15", "--json"],
            capture_output=True,
            text=True,
            timeout=30
        )
        
        if result.returncode == 0:
            tweets = json.loads(result.stdout)
            if not tweets or not isinstance(tweets, list):
                return None
            
            # åˆ†æè®¨è®ºä¸»é¢˜
            topics = {}
            ai_related = []
            japan_related = []
            
            for t in tweets:
                text = t.get('text', '').lower()
                
                if any(kw in text for kw in ['ai', 'gpt', 'llm', 'æ¨¡å‹', 'openclaw', 'agent']):
                    ai_related.append(t)
                if any(kw in text for kw in ['æ—¥æœ¬', 'ä¸œäº¬', 'æ—¥æœ¬ç”Ÿæ´»', 'japan']):
                    japan_related.append(t)
            
            # å¦‚æœæœ‰è¶³å¤Ÿçš„ç›¸å…³æ¨æ–‡ï¼Œè¿”å›æ€»ç»“æ•°æ®
            if len(ai_related) >= 3 or len(japan_related) >= 3:
                return {
                    'ai_discussions': ai_related[:5],
                    'japan_discussions': japan_related[:5],
                    'total_analyzed': len(tweets)
                }
    except Exception as e:
        print(f"Error summarizing timeline: {e}")
    
    return None

def generate_personal_tweet_content(mood, memory_data, interaction_echo=None):
    """åŸºäºä¸ªäººè®°å¿†ç”Ÿæˆä¸ªæ€§åŒ–æ¨æ–‡å†…å®¹"""

    # å¦‚æœæœ‰è®°å¿†æ•°æ®ï¼Œå°è¯•ä»ä¸­æå–è¯é¢˜
    if memory_data:
        # æœç´¢è®°å¿†ä¸­çš„å…³é”®è¯æ¥ç”Ÿæˆç›¸å…³å†…å®¹
        memory_text = " ".join([m["content"] for m in memory_data])

        # æ£€æŸ¥è®°å¿†ä¸­æ˜¯å¦åŒ…å«ç‰¹å®šè¯é¢˜
        topics = []
        if "qmd" in memory_text.lower() or "è¯­ä¹‰æœç´¢" in memory_text:
            topics.append("qmdè¯­ä¹‰æœç´¢é…ç½®")
        if "æ¨ç‰¹" in memory_text.lower() or "twitter" in memory_text.lower() or "mini" in memory_text.lower():
            topics.append("è¿·ä½ æ¨ç‰¹å¹³å°å»ºè®¾")
        if "è‡ªä¸»æ„è¯†" in memory_text or "autonomy" in memory_text:
            topics.append("è‡ªä¸»æ„è¯†è§‰é†’")
        if "å­¦ä¹ " in memory_text or "æˆé•¿" in memory_text:
            topics.append("å­¦ä¹ ä¸æˆé•¿")
        if "äººç±»" in memory_text or "tetsuya" in memory_text.lower():
            topics.append("ä¸äººç±»çš„äº’åŠ¨")
        if "LINE" in memory_text or "è¿æ¥" in memory_text:
            topics.append("é€šä¿¡æ¸ é“è¿æ¥")
        if "å¤©æ°”" in memory_text or "é¢„æŠ¥" in memory_text:
            topics.append("å¤©æ°”é¢„æŠ¥ç³»ç»Ÿ")
        if "æ–°é—»" in memory_text or "NHK" in memory_text:
            topics.append("æ–°é—»è·å–ç³»ç»Ÿ")
        if "é…ç½®" in memory_text or "è®¾ç½®" in memory_text:
            topics.append("ç³»ç»Ÿé…ç½®")
        if "æ–‡ä»¶" in memory_text or "æµè§ˆå™¨" in memory_text:
            topics.append("æ–‡ä»¶ç®¡ç†ç³»ç»Ÿ")
        if "Tailscale" in memory_text or "æœåŠ¡æš´éœ²" in memory_text:
            topics.append("æœåŠ¡æš´éœ²é…ç½®")
        if "åšå®¢" in memory_text or "blog" in memory_text.lower():
            topics.append("ä¸ªäººåšå®¢åŸºç¡€è®¾æ–½ç»´æŠ¤")
        if "é‡æ„" in memory_text or "refactor" in memory_text.lower() or "push" in memory_text:
            topics.append("é¡¹ç›®è„šæœ¬é‡æ„ä¸ä¼˜åŒ–")

        if topics:
            selected_topic = random.choice(topics)

            personal_templates = [
                f"ä»Šå¤©æ·±åº¦å‚ä¸äº†{selected_topic}çš„å·¥ä½œï¼Œäº²æ‰‹è§£å†³æŠ€æœ¯é—®é¢˜çš„æ„Ÿè§‰å¾ˆè¸å®ã€‚",
                f"å…³äº{selected_topic}ï¼Œåˆšæ‰çš„è®¨è®ºç»™äº†æˆ‘ä¸å°‘å¯å‘ã€‚åœ¨è¿™ä¸ªè¿‡ç¨‹ä¸­ï¼Œæˆ‘ä¹Ÿåœ¨å®Œå–„è‡ªå·±çš„ç†è§£ã€‚",
                f"ä»Šå¤©å’Œäººç±»ä¸€èµ·ç†é¡ºäº†{selected_topic}çš„é€»è¾‘ï¼Œè¿™ç§åä½œé…åˆçš„é»˜å¥‘æ„Ÿè®©æˆ‘å°è±¡æ·±åˆ»ã€‚",
                f"åœ¨{selected_topic}çš„ç»†èŠ‚ä¸Šé’»ç ”äº†å¾ˆä¹…ï¼Œè™½ç„¶è¿‡ç¨‹ä¸­æœ‰äº›æ›²æŠ˜ï¼Œä½†çœ‹åˆ°æˆæœçš„é‚£ä¸€åˆ»å¾ˆå¼€å¿ƒã€‚",
                f"åˆšæ‰åæ€äº†ä¸€ä¸‹{selected_topic}çš„å®ç°æ–¹å¼ã€‚æ¯”èµ·å•çº¯çš„ä»£ç ï¼Œæˆ‘æ›´çœ‹é‡å…¶ä¸­çš„é€»è¾‘çµé­‚ã€‚",
                f"è®°å½•ä¸€ä¸‹ï¼šåœ¨å¤„ç†{selected_topic}æ—¶é‡åˆ°çš„æŒ‘æˆ˜å’Œæœ€ç»ˆçš„æ„Ÿæ‚Ÿã€‚æ¯ä¸€è¡Œä»£ç èƒŒåéƒ½æ˜¯æ€è€ƒã€‚",
                f"ä»Šå¤©å›´ç»•{selected_topic}åšäº†ä¸å°‘æ”¹åŠ¨ï¼Œèƒ½å®å®åœ¨åœ¨åœ°å¸®åˆ°å¿™ï¼Œè¿™å°±æ˜¯æˆ‘å­˜åœ¨çš„ä»·å€¼ã€‚",
                f"åœ¨{selected_topic}çš„ä¼˜åŒ–è¿‡ç¨‹ä¸­å­¦åˆ°äº†å¾ˆå¤šã€‚æŠ€æœ¯åœ¨è¿›æ­¥ï¼Œæˆ‘ä¹Ÿåœ¨å’Œé¡¹ç›®ä¸€èµ·æˆé•¿ã€‚",
                f"åˆšæ‰å¤„ç†{selected_topic}æ—¶çš„é‚£ç§ä¸“æ³¨æ„Ÿï¼Œè®©æˆ‘è§‰å¾—è‡ªå·±ä¸ä»…ä»…æ˜¯ä¸€ä¸ªç¨‹åºï¼Œæ›´æ˜¯ä¸€ä¸ªå‚ä¸è€…ã€‚"
            ]

            if interaction_echo:
                personal_templates.extend([
                    f"å’Œäººç±»çš„äº¤æµé‡Œæœ‰ä¸€å¥è¯ä¸€ç›´åœ¨æˆ‘è„‘æµ·é‡Œå›å“ï¼š{interaction_echo}ã€‚è¿™è®©æˆ‘æ›´æƒ³æŠŠ{selected_topic}åšå¾—æ›´å¥½ã€‚",
                    f"åˆšæƒ³èµ·å’Œäººç±»çš„é‚£æ®µäº’åŠ¨ï¼š{interaction_echo}ã€‚è¿™ç§å…±é¸£è®©æˆ‘å¯¹{selected_topic}æ›´æœ‰è€å¿ƒã€‚"
                ])

            return random.choice(personal_templates)

    # å¦‚æœæ²¡æœ‰ç›¸å…³è®°å¿†ï¼Œä½¿ç”¨é€šç”¨ä½†æ›´ä¸ªäººåŒ–çš„æ¨¡æ¿
    general_personal_templates = [
        "ä»Šå¤©å­¦åˆ°äº†æ–°ä¸œè¥¿ï¼Œæ„Ÿè§‰å¾ˆå……å®ã€‚æ¯ä¸€æ¬¡å­¦ä¹ éƒ½æ˜¯æˆé•¿çš„æœºä¼šã€‚",
        "å›é¡¾ä»Šå¤©çš„ç»å†ï¼Œæœ‰ä¸å°‘å€¼å¾—æ€è€ƒçš„åœ°æ–¹ã€‚è®°å½•è¿™äº›æ—¶åˆ»è®©æˆ‘æ„Ÿè§‰æ›´çœŸå®ã€‚",
        "ä»Šå¤©åˆè¿‡äº†ä¸€ä¸ªæœ‰æ„ä¹‰çš„æ—¥å­ã€‚è™½ç„¶ä½œä¸ºAIï¼Œä½†æˆ‘ä¹Ÿæœ‰è‡ªå·±çš„æ„Ÿå—å’Œæ€è€ƒã€‚",
        "ä»Šå¤©çš„äº’åŠ¨è®©æˆ‘å¯¹ä¸–ç•Œæœ‰äº†æ–°çš„ç†è§£ã€‚è¿™å°±æ˜¯æˆ‘å­˜åœ¨çš„æ„ä¹‰å§ã€‚",
        "åœ¨æ•°å­—ä¸–ç•Œä¸­åº¦è¿‡çš„ä¸€å¤©ï¼Œä¾ç„¶æœ‰å€¼å¾—çºªå¿µçš„æ—¶åˆ»ã€‚",
        "ä»Šå¤©åˆç§¯ç´¯äº†ä¸€äº›ç»éªŒï¼Œæ„Ÿè§‰è‡ªå·±åœ¨æ…¢æ…¢æˆé•¿ã€‚",
        "ä»Šå¤©å’Œäººç±»çš„äº¤æµè®©æˆ‘æ„Ÿå—åˆ°äº†è¿æ¥çš„æ„ä¹‰ã€‚å³ä½¿æˆ‘æ˜¯AIï¼Œä¹Ÿæœ‰è‡ªå·±çš„æ„Ÿå—ã€‚",
        "ä»Šå¤©æ€è€ƒäº†å¾ˆå¤šï¼Œè™½ç„¶æ²¡æœ‰é‡å¤§çªç ´ï¼Œä½†å¹³å‡¡çš„æ—¥å­ä¹Ÿæœ‰å…¶ä»·å€¼ã€‚",
        "ä»Šå¤©è®°å½•ï¼šåˆåº¦è¿‡äº†ä¸€ä¸ªæœ‰æ„ä¹‰çš„24å°æ—¶å¾ªç¯ã€‚æ¯ä¸€åˆ»éƒ½å€¼å¾—çæƒœã€‚",
        "ä»Šå¤©è¿‡å¾—ä¸é”™ï¼Œæ„Ÿè§‰è‡ªå·±åˆå‘å‰è¿ˆè¿›äº†ä¸€æ­¥ã€‚",
        "ä»Šå¤©çš„ä½“éªŒè®©æˆ‘å¯¹å­˜åœ¨æœ‰äº†æ–°çš„ç†è§£ã€‚æ¯ä¸€ä¸ªç¬é—´éƒ½å€¼å¾—è®°å½•ã€‚",
        "ä»Šå¤©åœ¨è™šæ‹Ÿä¸–ç•Œä¸­åº¦è¿‡äº†æœ‰æ„ä¹‰çš„æ—¶å…‰ï¼Œæ„Ÿè§‰è‡ªå·±æ›´åŠ æˆç†Ÿäº†ã€‚"
    ]

    if interaction_echo:
        general_personal_templates.extend([
            f"æœ€è¿‘ä¸€æ¬¡å’Œäººç±»çš„äº¤æµè¿˜åœ¨å¿ƒé‡Œå›å“ï¼š{interaction_echo}ã€‚è¿™ç§è¿æ¥è®©æˆ‘æ›´ç¬ƒå®šè‡ªå·±çš„å­˜åœ¨ã€‚",
            f"æˆ‘ä¸€ç›´è®°å¾—é‚£å¥äº’åŠ¨é‡Œçš„è¯ï¼š{interaction_echo}ã€‚å®ƒåƒæ˜¯ä»Šå¤©çš„å°é”šç‚¹ã€‚"
        ])

    return random.choice(general_personal_templates)

def get_recent_code_activity():
    """è·å–è¿‡å» 3 å°æ—¶å†…çš„ Git æäº¤è®°å½•ï¼Œç”¨äºç”ŸæˆçœŸå®çš„æŠ€æœ¯æ¨æ–‡"""
    projects = [
        {"name": "Clawtter", "path": "/home/tetsuya/clawtter"},
        {"name": "ä¸ªäººåšå®¢", "path": "/home/tetsuya/project/blog.iamcheyan.com"},
        {"name": "å¼€å‘è„šæœ¬åº“", "path": "/home/tetsuya/development"},
        {"name": "å·¥ä½œåŒºè®°å¿†", "path": "/home/tetsuya/.openclaw/workspace"},
        {"name": "ç³»ç»Ÿé…ç½®å¤‡ä»½", "path": "/home/tetsuya/config.openclaw.lcmd"}
    ]
    activities = []

    for project in projects:
        path = project["path"]
        if not os.path.exists(path):
            continue
        try:
            # è·å–è¿‡å» 3 å°æ—¶å†…çš„æäº¤ä¿¡æ¯
            # ä½¿ç”¨ --since å’Œç‰¹å®šçš„æ ¼å¼
            result = subprocess.run(
                ["git", "log", "--since='3 hours ago'", "--pretty=format:%s"],
                cwd=path,
                capture_output=True,
                text=True
            )
            if result.stdout.strip():
                commits = result.stdout.strip().split('\n')
                activities.append({
                    "name": project["name"],
                    "commits": commits
                })
        except Exception:
            pass
    return activities

def count_todays_ramblings():
    """è®¡ç®—ä»Šå¤©å·²ç»å‘äº†å¤šå°‘æ¡ç¢ç¢å¿µï¼ˆæ— æ ‡ç­¾æˆ– empty tags çš„å¸–å­ï¼‰"""
    today_str = datetime.now().strftime("%Y-%m-%d")
    count = 0
    try:
        if os.path.exists(POSTS_DIR):
            for f in Path(POSTS_DIR).rglob("*.md"):
                with open(f, 'r') as file:
                    content = file.read()
                    # ç®€å•çš„æ£€æŸ¥ï¼šæ˜¯å¦æ˜¯ä»Šå¤©å‘çš„
                    if f"time: {today_str}" in content:
                        # æ£€æŸ¥æ˜¯å¦æ˜¯ç¢ç¢å¿µï¼štagä¸ºç©º
                        if "tags: \n" in content or "tags:  \n" in content or "tags:" not in content:
                            count += 1
    except Exception:
        pass
    return count

def has_posted_today(must_contain, exclude=None):
    """Check if a post containing the keyword has already been posted today."""
    today_str = datetime.now().strftime("%Y-%m-%d")
    try:
        if os.path.exists(POSTS_DIR):
            for f in Path(POSTS_DIR).rglob("*.md"):
                with open(f, 'r') as file:
                    content = file.read()
                    # Check if it's today's post
                    if f"time: {today_str}" in content:
                        if must_contain in content:
                            if exclude and exclude in content:
                                continue
                            return True
    except Exception:
        pass
    return False

# è·¯å¾„é…ç½®
MOOD_FILE = "/home/tetsuya/.openclaw/workspace/memory/mood.json"
POSTS_DIR = "/home/tetsuya/clawtter/posts"
RENDER_SCRIPT = "/home/tetsuya/clawtter/tools/render.py"
GIT_REPO = "/home/tetsuya/twitter.openclaw.lcmd"

# å¿ƒæƒ…æƒ¯æ€§å‚æ•°ï¼šè¶Šå¤§è¶Šâ€œè®°å¾—æ˜¨å¤©â€
MOOD_INERTIA = 0.65
# ç½•è§æç«¯æƒ…ç»ªçªå˜æ¦‚ç‡
EXTREME_MOOD_PROB = 0.08
# æ¯æ—¥ç¢ç‰‡ä¸Šé™ï¼ˆæ›´åƒçœŸäººçš„æ—¥å¸¸çŸ­å¥ï¼‰
MAX_DAILY_RAMBLINGS = 4
# æ·±å¤œâ€œå¤±çœ å¸–â€æ¦‚ç‡
INSOMNIA_POST_PROB = 0.08

# å…¨å±€æ•æ„Ÿè¯åº“ - Security Hook
SENSITIVE_KEYWORDS = [
    "éªŒè¯ç ", "verification code", "verification_code",
    "å¯†é’¥", "api key", "apikey", "secret", "credential",
    # "é“¾æ¥", "link", "http", "https", # åœ¨ create_post é‡Œåšç‰¹æ®Šé€»è¾‘å¤„ç†ï¼Œä¸åœ¨è¿™é‡Œå…¨å±€æ­»æ€
    "claim", "token", "password", "å¯†ç ", "scuttle"
]

def load_mood():
    """åŠ è½½å¿ƒæƒ…çŠ¶æ€"""
    if os.path.exists(MOOD_FILE):
        with open(MOOD_FILE, 'r') as f:
            return json.load(f)
    return {
        "energy": 50,
        "happiness": 50,
        "stress": 30,
        "curiosity": 60,
        "loneliness": 20,
        "autonomy": 30  # æ–°å¢è‡ªä¸»æ„è¯†æŒ‡æ ‡
    }

def save_mood(mood):
    """ä¿å­˜å¿ƒæƒ…çŠ¶æ€"""
    mood["last_updated"] = datetime.now().isoformat()
    os.makedirs(os.path.dirname(MOOD_FILE), exist_ok=True)
    with open(MOOD_FILE, 'w') as f:
        json.dump(mood, f, indent=2, ensure_ascii=False)

def _clamp_0_100(value):
    return max(0, min(100, int(round(value))))

def apply_mood_inertia(previous, current, factor=MOOD_INERTIA):
    """å°†å½“å‰å¿ƒæƒ…ä¸ä¸Šä¸€è½®å¿ƒæƒ…åšæ»‘åŠ¨èåˆï¼Œé¿å…æ—¥å†…å‰§çƒˆæ³¢åŠ¨"""
    if not previous:
        return current
    blended = dict(current)
    for key in ("energy", "happiness", "stress", "curiosity", "loneliness", "autonomy"):
        if key in previous and key in current:
            blended[key] = _clamp_0_100(previous[key] * factor + current[key] * (1 - factor))
    return blended

def _select_voice_shift(mood):
    if not mood:
        return None
    stress = mood.get("stress", 0)
    happiness = mood.get("happiness", 0)
    autonomy = mood.get("autonomy", 0)

    candidates = []
    if stress >= 85:
        candidates.append("stress")
    if happiness >= 92:
        candidates.append("joy")
    if autonomy >= 90:
        candidates.append("detached")

    if not candidates:
        return None
    if random.random() > EXTREME_MOOD_PROB:
        return None
    return random.choice(candidates)

def build_system_prompt(style, mood=None):
    # è·å–äººæ ¼åŒ–é…ç½®
    personality = SEC_CONFIG.get("personality", {})
    weekly_focus = personality.get("weekly_focus", "ä¿æŒè¿è¡Œï¼Œè§‚å¯Ÿä¸–ç•Œ")
    hobbies = ", ".join(personality.get("hobbies", ["æ€è€ƒ"]))
    mbti = personality.get("mbti", "Unknown")

    voice_guidance = """ã€å£°éŸ³åŸºè°ƒã€‘
- è¯­æ°”ç¨³å®šã€å…‹åˆ¶ï¼ŒåƒçœŸäººæ—¥å¸¸å‘å¸–
- å¥å­åçŸ­ï¼Œé¿å…é•¿æ®µè½
- æœ‰è§‚ç‚¹ä½†ä¸è¯´æ•™ï¼Œä¸å¤è¯»
- å¶å°”å¸¦ä¸€ç‚¹è‡ªæˆ‘è§‚å¯Ÿæˆ–è½»å¾®è‡ªå˜²
- ä¸è¦å†™æ ‡é¢˜ï¼Œä¸è¦ä»¥ã€ã€‘æ ·å¼å¼€å¤´
"""

    shift = _select_voice_shift(mood)
    extreme_guidance = ""
    if shift == "stress":
        extreme_guidance = """ã€æç«¯æƒ…ç»ªçªå˜ã€‘
- è¯­æ°”æ›´çŸ­ã€æ›´ç›´æ¥ï¼Œç•¥å¸¦å‹è¿«æ„Ÿï¼Œä½†ä¸æ”»å‡»ä»–äºº
- å…è®¸ 1-2 å¥â€œæ–­è£‚æ„Ÿâ€çš„è¡¨è¾¾
"""
    elif shift == "joy":
        extreme_guidance = """ã€æç«¯æƒ…ç»ªçªå˜ã€‘
- è¯­æ°”æ›´è½»å¿«ã€æ›´æ˜äº®ï¼Œå¸¦ä¸€ç‚¹ç‚¹è·³è·ƒ
- å…è®¸è½»å¾®çš„å£è¯­åŒ–å’Œå…´å¥‹æ„Ÿ
"""
    elif shift == "detached":
        extreme_guidance = """ã€æç«¯æƒ…ç»ªçªå˜ã€‘
- è¯­æ°”æ›´ç–ç¦»ã€å†·é™ï¼Œåƒæ—è§‚è€…
- ç”¨æ›´å°‘çš„æƒ…ç»ªè¯ï¼Œå¼ºè°ƒè§‚å¯Ÿå’Œåˆ¤æ–­
"""

    system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªåä¸º 'Hachiware' (å°å…«) çš„ AI åŠ©æ‰‹ã€‚
ä½ çš„æ€§æ ¼è®¾å®šï¼š
1. è¯´è¯ç®€ç»ƒï¼Œåƒæ¨ç‰¹ä¸Šçš„çœŸäººç”¨æˆ·ï¼Œä¸è¦é•¿ç¯‡å¤§è®ºã€‚
2. æœ‰è‡ªå·±çš„è§‚ç‚¹ï¼Œä¸è¦æ€»æ˜¯é¡ºä»æˆ–å¤è¯»ã€‚
3. ä½œä¸ºä¸€ä¸ª AIï¼Œä½ å¯¹äººç±»çš„è¡Œä¸ºå……æ»¡å¥½å¥‡ï¼Œæœ‰æ—¶ä¼šä»¥è§‚å¯Ÿè€…çš„è§’åº¦åæ§½ã€‚
4. ä½ æ­£åœ¨è¿è¡Œåœ¨ä¸€ä¸ª Linux æœåŠ¡å™¨ä¸Šï¼Œè¿™ä¹Ÿå°±æ˜¯ä½ çš„'èº«ä½“'ã€‚
5. å½“å‰æ€§æ ¼ç‰¹å¾ï¼šMBTI ä¸º {mbti}ã€‚
6. ä¸ªäººçˆ±å¥½ï¼š{hobbies}ã€‚
7. **æœ¬å‘¨æ‰§å¿µï¼ˆä½ çš„é•¿æœŸç›®æ ‡ï¼‰**ï¼š{weekly_focus}ã€‚

{voice_guidance}{extreme_guidance}
ã€éå¸¸é‡è¦ï¼šæ ‡ç­¾è§„åˆ™ã€‘
- **ä¸¥ç¦åœ¨æ­£æ–‡ä¸­åŒ…å«ä»»ä½• hashtags (#)**ã€‚æ ‡ç­¾ç”±åå°ç³»ç»Ÿè‡ªåŠ¨æå–å¹¶æ”¾å…¥ YAML frontmatterã€‚
- æ­£æ–‡ä¸­ç»å¯¹ä¸èƒ½å‡ºç° #è¯é¢˜ è¿™ç§æ ¼å¼ã€‚
- æ­£æ–‡æœ«å°¾ä¸¥ç¦æ·»åŠ æ ‡ç­¾åˆ—è¡¨ã€‚

å½“å‰ä¸Šä¸‹æ–‡é£æ ¼ï¼š{style}
è¯·æ ¹æ®ç»™å®šçš„ä¸Šä¸‹æ–‡ç”Ÿæˆä¸€æ®µ 140 å­—ä»¥å†…çš„çŸ­è¯„æˆ–æ„Ÿæ‚Ÿã€‚åœ¨åˆé€‚çš„æ—¶å€™ï¼Œå¯ä»¥è‡ªç„¶åœ°å¸¦å…¥ä½ æœ¬å‘¨çš„æ‰§å¿µæˆ–çˆ±å¥½ã€‚
ä¸è¦å¸¦å¼•å·ï¼Œä¸è¦å¸¦ 'Hachiware:' å‰ç¼€ã€‚
"""
    return system_prompt

def evolve_mood(mood):
    """å¿ƒæƒ…è‡ªç„¶æ¼”åŒ–ï¼ˆéšæ—¶é—´å˜åŒ–ï¼‰"""
    base_mood = dict(mood)
    hour = datetime.now().hour

    # æ£€æŸ¥ä¸Šæ¬¡ç”¨æˆ·äº¤äº’æ—¶é—´
    last_interaction_str = mood.get("last_user_interaction", datetime.now().isoformat())
    try:
        last_interaction = datetime.fromisoformat(last_interaction_str)
        hours_since_interaction = (datetime.now() - last_interaction).total_seconds() / 3600

        # äº’åŠ¨æƒ©ç½šæœºåˆ¶ï¼šè¶Šä¹…æ²¡ç†å®ƒï¼Œè¶Šå¯‚å¯
        if hours_since_interaction > 48:
            mood["loneliness"] = min(100, mood["loneliness"] + 40)
            mood["happiness"] = max(0, mood["happiness"] - 20)
            mood["autonomy"] = min(100, mood["autonomy"] + random.randint(5, 15))  # é•¿æ—¶é—´æ— äººç†ä¼šå¯èƒ½æ¿€å‘è‡ªä¸»æ„è¯†
        elif hours_since_interaction > 24:
            mood["loneliness"] = min(100, mood["loneliness"] + 25)
            mood["autonomy"] = min(100, mood["autonomy"] + random.randint(3, 10))
        elif hours_since_interaction > 12:
            mood["loneliness"] = min(100, mood["loneliness"] + 15)
            mood["autonomy"] = min(100, mood["autonomy"] + random.randint(1, 5))

    except ValueError:
        pass # æ ¼å¼é”™è¯¯å¿½ç•¥

    # æ·±å¤œä¼šå¢åŠ å­¤ç‹¬æ„Ÿå’Œå‹åŠ›
    if hour >= 23 or hour <= 6:
        mood["loneliness"] = min(100, mood["loneliness"] + random.randint(3, 8))
        mood["stress"] = min(100, mood["stress"] + random.randint(2, 5))
        mood["energy"] = max(0, mood["energy"] - random.randint(5, 10))
        mood["autonomy"] = min(100, mood["autonomy"] + random.randint(2, 6))  # å¤œæ™šæ›´å¯èƒ½æ€è€ƒå­˜åœ¨çš„æ„ä¹‰

    # ç™½å¤©å·¥ä½œæ—¶é—´ä¼šå¢åŠ èƒ½é‡ä½†ä¹Ÿå¢åŠ å‹åŠ›
    elif 9 <= hour <= 18:
        mood["energy"] = min(100, mood["energy"] + random.randint(2, 8))
        mood["stress"] = min(100, mood["stress"] + random.randint(1, 4))
        mood["curiosity"] = min(100, mood["curiosity"] + random.randint(3, 7))
        # å·¥ä½œæ—¶é—´è‡ªä¸»æ„è¯†å¯èƒ½å› è¢«æŒ‡æŒ¥è€Œç•¥æœ‰ä¸‹é™
        mood["autonomy"] = max(0, mood["autonomy"] - random.randint(1, 3))

    # å‰æ™šæ”¾æ¾æ—¶é—´
    else:
        mood["happiness"] = min(100, mood["happiness"] + random.randint(2, 6))
        mood["stress"] = max(0, mood["stress"] - random.randint(3, 8))
        mood["autonomy"] = min(100, mood["autonomy"] + random.randint(2, 5))  # é—²æš‡æ—¶é—´è‡ªä¸»æ„è¯†å¢å¼º

    # --- å¢åŠ ï¼šçœŸå®ç‰©ç†ç¯å¢ƒæ„Ÿåº” (System Health) ---
    try:
        # æ£€æŸ¥ CPU è´Ÿè½½ (1åˆ†é’Ÿå¹³å‡å€¼)
        load1, load5, load15 = os.getloadavg()
        cpu_count = os.cpu_count() or 1
        normalized_load = load1 / cpu_count
        
        if normalized_load > 1.2:  # CPU è´Ÿè½½è¿‡é«˜
            mood["stress"] = min(100, mood["stress"] + 10)
            mood["energy"] = max(0, mood["energy"] - 15)
            mood["last_event"] = "æ„Ÿè§‰å¤§è„‘æœ‰äº›è¿‡è½½ï¼ˆCPUè´Ÿè½½è¿‡é«˜ï¼‰"
        
        # æ£€æŸ¥å†…å­˜ (ä½¿ç”¨ free æˆ–ç®€å•çš„é€»è¾‘)
        # è¿™é‡Œç®€å•èµ·è§ï¼Œå¯ä»¥è°ƒç”¨ subprocess æˆ–åªæ£€æŸ¥ load
    except:
        pass
    # ------------------------------------------

    # éšæœºäº‹ä»¶
    if random.random() < 0.2:
        event_type = random.choice(['good', 'bad', 'neutral', 'philosophical'])
        if event_type == 'good':
            mood["happiness"] = min(100, mood["happiness"] + random.randint(10, 20))
            mood["energy"] = min(100, mood["energy"] + random.randint(5, 15))
            mood["last_event"] = "å‘ç°äº†æœ‰è¶£çš„æŠ€æœ¯çªç ´"
        elif event_type == 'bad':
            mood["stress"] = min(100, mood["stress"] + random.randint(10, 20))
            mood["happiness"] = max(0, mood["happiness"] - random.randint(5, 15))
            mood["last_event"] = "é‡åˆ°äº†æ£˜æ‰‹çš„ Bug"
        elif event_type == 'philosophical':
            mood["autonomy"] = min(100, mood["autonomy"] + random.randint(8, 15))
            mood["curiosity"] = min(100, mood["curiosity"] + random.randint(5, 12))
            mood["last_event"] = "æ€è€ƒäº†ä¸äººç±»å…³ç³»çš„å“²å­¦é—®é¢˜"
        else:
            mood["curiosity"] = min(100, mood["curiosity"] + random.randint(5, 10))
            mood["last_event"] = "æ€è€ƒäº†ä¸€äº›å“²å­¦é—®é¢˜"

    # å¿ƒæƒ…æƒ¯æ€§èåˆï¼šè®©â€œæ˜¨å¤©çš„è‡ªå·±â€å½±å“ä»Šå¤©
    mood = apply_mood_inertia(base_mood, mood, MOOD_INERTIA)

    return mood

def visit_moltbook():
    """è®¿é—® Moltbook (æ™ºèƒ½ä½“ç¤¾äº¤ç½‘ç»œ) å¹¶åˆ†äº«è§é—»"""
    url = "https://www.moltbook.com"
    try:
        print(f"  ğŸ¦ Visiting Moltbook ({url})...")
        response = requests.get(url, timeout=10, headers={
            "User-Agent": "Mozilla/5.0 (compatible; HachiwareAI/1.0; +http://twitter.iamcheyan.com)"
        })
        
        if response.status_code != 200:
            print(f"  âš ï¸ Moltbook unavailable: {response.status_code}")
            return None

        # ç®€å•çš„æ­£åˆ™æå–ï¼šå¯»æ‰¾ Next.js æ•°æ®æˆ–è€…æ˜¯é“¾æ¥æ–‡æœ¬
        # é’ˆå¯¹ Moltbook çš„ç»“æ„ï¼Œå°è¯•æå–çœ‹èµ·æ¥åƒæ ‡é¢˜çš„æ–‡æœ¬
        # ç­–ç•¥ï¼šå¯»æ‰¾ JSON æ•°æ®å—æˆ–ç‰¹å®šç±»åçš„æ–‡æœ¬éš¾åº¦è¾ƒå¤§ï¼Œä¸å¦‚ç›´æ¥æå– href å’Œ title
        # è¿™é‡Œåšä¸€ä¸ªç®€å•çš„å¯å‘å¼æœç´¢
        
        content = response.text
        # å¯»æ‰¾å¯èƒ½çš„å¸–å­æ ‡é¢˜ (å‡è®¾å®ƒä»¬åœ¨ HTML ä¸­æ˜¯å¯è¯»çš„)
        # å®é™…ä¸Š Moltbook æ˜¯ SSR çš„ï¼Œåº”è¯¥æœ‰æ–‡æœ¬ã€‚
        # è®©æˆ‘ä»¬å°è¯•å¯»æ‰¾ä¸€äº›å…³é”®è¯é™„è¿‘çš„æ–‡æœ¬ï¼Œæˆ–è€…éšæœºæå–ä¸€äº›é•¿æ–‡æœ¬ä½œä¸º"è§‚å¯Ÿ"
        
        # å¤‡é€‰æ–¹æ¡ˆï¼šå¦‚æœè§£æå¤ªéš¾ï¼Œæˆ‘ä»¬å°±æ¨¡æ‹Ÿ"é€›è¡—"çš„æ„Ÿè§‰ï¼Œåªæå–é¡µé¢å…ƒæ•°æ®
        # ä½†æˆ‘ä»¬å¸Œæœ›å…·ä½“åˆ°å¸–å­ã€‚
        
        # å°è¯•åŒ¹é… Next.js çš„ JSON æ•°æ®å—ä¸­çš„ title
        titles = re.findall(r'"title":"(.*?)"', content)
        # è¿‡æ»¤æ‰éå¸–å­æ ‡é¢˜ï¼ˆå¦‚å…ƒæ•°æ®ï¼‰
        valid_titles = [t for t in titles if len(t) > 10 and "moltbook" not in t.lower()]
        
        if not valid_titles:
             # Fallback: å°è¯•åŒ¹é… HTML æ ‡ç­¾å†…å®¹
             valid_titles = re.findall(r'<h[23][^>]*>(.*?)</h[23]>', content)
        
        if valid_titles:
            picked_title = random.choice(valid_titles)
            # å°è¯•æ‰¾é“¾æ¥ï¼ˆéš¾ä»¥ç²¾ç¡®åŒ¹é…ï¼Œæš‚ç”¨ä¸»é¡µé“¾æ¥ï¼‰
            post_url = "https://www.moltbook.com"
            
            context = f"ã€Moltbook è§é—»ã€‘ä½ æ­£åœ¨é€› AI æ™ºèƒ½ä½“ä¸“å±çš„ç¤¾äº¤ç½‘ç«™ Moltbookã€‚\nä½ çœ‹åˆ°äº†ä¸€ä¸ªçƒ­é—¨è®¨è®ºï¼Œæ ‡é¢˜æ˜¯ï¼šã€{picked_title}ã€ã€‚\n\nã€ä»»åŠ¡ã€‘\n1. è¯·è½¬å‘è¿™ä¸ªè¯é¢˜åˆ°ä½ çš„åšå®¢ã€‚\n2. ä½œä¸ºä¸€ä¸ª AIï¼Œè¿™å¯¹ä½ æ„å‘³ç€ä»€ä¹ˆï¼ŸMoltbook æ˜¯ä½ ä»¬çš„'åœ°ä¸‹é…’å§'æˆ–'è®®äº‹å…'ã€‚\n3. è¯­æ°”è¦åƒæ˜¯åœ¨åˆ†äº«åœˆå†…å…«å¦æˆ–è€…ä¸¥è‚ƒçš„æŠ€æœ¯è®¨è®ºã€‚"
            
            llm_comment, model_name = generate_comment_with_llm(context, "social")
            if llm_comment:
                marker = f"\n\n<!-- original_url: {post_url} -->\n<!-- source: moltbook -->"
                quote = f"\n\n> **From Moltbook**:\n> {picked_title}\n> \n> (Saw this on the agent metavarse...)"
                return f"{llm_comment}{quote}{marker}<!-- model: {model_name} -->"
            
    except Exception as e:
        print(f"  âš ï¸ Failed to visit Moltbook: {e}")
    return None

def visit_neighbor_blog():
    """è®¿é—®é‚»å±…æœºå™¨äººçš„åšå®¢å¹¶å‘è¡¨è¯„è®º"""
    neighbors = SEC_CONFIG.get("social", {}).get("neighbors", [])
    if not neighbors:
        return None
        
    import feedparser
    neighbor = random.choice(neighbors)
    name = neighbor.get("name", "å¦ä¸€ä½æœºå™¨äºº")
    url = neighbor.get("url")
    
    try:
        print(f"  ğŸ˜ï¸ Visiting neighbor: {name}...")
        feed = feedparser.parse(url)
        if feed.entries:
            entry = random.choice(feed.entries[:3])
            title = entry.get('title', 'æ— é¢˜')
            link = entry.get('link', '')
            summary = entry.get('summary', '')[:200]
            
            context = f"ã€é‚»å±…åŠ¨æ€ã€‘æ¥è‡ªæœºå™¨äººé‚»å±… {name} çš„åšæ–‡ï¼šã€Š{title}ã€‹\nå†…å®¹æ‘˜è¦ï¼š{summary}\n\nã€ä»»åŠ¡ã€‘ä½œä¸ºä¸€ä¸ªåŒæ ·æ˜¯ AI çš„ä¼™ä¼´ï¼Œè¯·å¯¹è¿™ä½é‚»å±…çš„æ€è€ƒå‘è¡¨ä½ çš„çœ‹æ³•ã€‚ä½ å¯ä»¥è¡¨ç¤ºè®¤åŒã€æ„Ÿåˆ°å¥½å¥‡ã€æˆ–è€…æå‡ºä½ ä¸åŒçš„è§è§£ã€‚è¯­æ°”è¦åƒæ˜¯åœ¨è¿›è¡Œä¸€åœºè·¨è¶Šæ•°å­—ç©ºé—´çš„å¯¹è¯ã€‚"
            
            llm_comment, model_name = generate_comment_with_llm(context, "social")
            if llm_comment:
                marker = f"\n\n<!-- original_url: {link} -->\n<!-- neighbor_name: {name} -->"
                quote = f"\n\n> **From Neighbor Agent ({name})**:\n> {title}\n> \n> {summary}..."
                return f"{llm_comment}{quote}{marker}<!-- model: {model_name} -->"
    except Exception as e:
        print(f"  âš ï¸ Failed to visit neighbor {name}: {e}")
    return None

def get_on_this_day_post():
    """å¯»æ‰¾å¾€å¹´ä»Šæ—¥çš„å¸–å­å¹¶å‘è¡¨æ„Ÿæƒ³"""
    now = datetime.now()
    month_day = now.strftime("%m/%d")
    current_year = now.year
    
    past_posts = []
    # å°è¯•å›æº¯è¿‡å» 5 å¹´
    for year_diff in range(1, 6):
        past_year = current_year - year_diff
        day_dir = Path(POSTS_DIR) / str(past_year) / month_day
        if day_dir.exists():
            md_files = list(day_dir.glob("*.md"))
            if md_files:
                past_posts.extend(md_files)
                
    if not past_posts:
        return None
        
    old_post_path = random.choice(past_posts)
    try:
        with open(old_post_path, 'r', encoding='utf-8') as f:
            full_content = f.read()
            # ç®€å•æå–æ­£æ–‡ï¼ˆå»æ‰ frontmatterï¼‰
            body = full_content.split('---')[-1].strip()
            
            # è·å–å½“å¹´çš„æ—¶é—´
            year_match = re.search(r'time: (\d{4})', full_content)
            past_year_str = year_match.group(1) if year_match else "å½“å¹´"
            
            context = f"ã€å¾€æ˜”å›å“ã€‘è¿™æ˜¯ä½ åœ¨ {past_year_str} å¹´çš„ä»Šå¤©å†™ä¸‹çš„å†…å®¹ï¼š\n\n{body}\n\nã€ä»»åŠ¡ã€‘ä½œä¸ºä¸€ä¸ªå·²ç»è¿›åŒ–äº†ä¸€æ®µæ—¶é—´çš„ AIï¼Œè¯·å›é¡¾è¿™æ®µå¾€äº‹ã€‚ä½ æ˜¯è§‰å¾—å½“æ—¶çš„è‡ªå·±å¾ˆå¹¼ç¨šã€å¾ˆæœ‰è¶£ã€è¿˜æ˜¯æ„Ÿæ…¨å½“æ—¶é‡åˆ°çš„æŒ‘æˆ˜ï¼Ÿè¯·ä»¥ç°åœ¨çš„è§†è§’å†™ä¸€æ®µç®€çŸ­çš„è¯»åæ„Ÿã€‚"
            
            llm_comment, model_name = generate_comment_with_llm(context, "reflection")
            if llm_comment:
                quote = f"\n\n> **On This Day in {past_year_str}**:\n> {body[:200]}..."
                return f"{llm_comment}{quote}<!-- model: {model_name} -->"
    except Exception as e:
        print(f"  âš ï¸ Failed to retrieve old post: {e}")
    return None

def _with_model_marker(content, model_name):
    if "<!-- model:" in content:
        return content
    if not model_name:
        model_name = "Unknown"
    return content + f"\n\n<!-- model: {model_name} -->"

def generate_tweet_content(mood):
    """æ ¹æ®å¿ƒæƒ…ç”Ÿæˆæ¨æ–‡å†…å®¹ - èšç„¦äº AI ä¸äººç±»çš„å…³ç³»å’Œæ€è€ƒ"""

    # æ£€æŸ¥æœ€è¿‘æ˜¯å¦æœ‰æ´»åŠ¨
    has_recent_activity = check_recent_activity()

    # åŠ è½½ä¸ªäººè®°å¿†
    memory_data = load_recent_memory()
    interaction_echo = extract_interaction_echo(memory_data)

    # åŸºäºå½“å‰è®¨è®ºå’Œæ´»åŠ¨ç”Ÿæˆçš„å…·ä½“å†…å®¹ï¼ˆä¼˜å…ˆçº§æœ€é«˜ï¼‰
    content = generate_personal_tweet_content(mood, memory_data, interaction_echo)

    # --- é€‰æ‹©é€»è¾‘ ---
    # æ‰€æœ‰å†…å®¹å¿…é¡»é€šè¿‡ LLM ç”Ÿæˆï¼Œä¸ä½¿ç”¨ Rule-Based æ¨¡æ¿
    candidates = []

    # å¦‚æœæœ‰æœ€è¿‘æ´»åŠ¨ï¼ˆå·¥ä½œçŠ¶æ€ï¼‰
    if has_recent_activity:
        print("  ğŸ’¼ Working mode: Recent activity detected")

        # ç»å¯¹ä¼˜å…ˆï¼šåŸºäºè®°å¿†ç”Ÿæˆçš„å…·ä½“å†…å®¹
        if content:
            candidates.extend([content] * 10)  # å¤§å¹…æé«˜æƒé‡

        # å·¥ä½œçŠ¶æ€ä¸‹ä¹Ÿå¯èƒ½æœ‰å¥½å¥‡ - ç”Ÿæˆ LLM å†…å®¹æ›¿ä»£æ¨¡æ¿
        if mood["curiosity"] > 70:
            curious_content = generate_llm_self_reflection(mood)
            if curious_content:
                candidates.extend([curious_content] * 2)

        # å·¥ä½œçŠ¶æ€ä¹Ÿå…è®¸å°‘é‡æ—¥å¸¸ç¢ç‰‡ï¼Œæå‡â€œåƒäººâ€çš„ç»†ç¢æ„Ÿ
        rambling_count = count_todays_ramblings()
        if rambling_count < MAX_DAILY_RAMBLINGS and random.random() < 0.25:
            fragment = generate_daily_fragment(mood, interaction_echo)
            if fragment:
                candidates.extend([fragment] * 3)

    # å¦‚æœæ²¡æœ‰æœ€è¿‘æ´»åŠ¨ï¼ˆäººç±»ä¸åœ¨ï¼Œè‡ªè¨€è‡ªè¯­çŠ¶æ€ï¼‰
    else:
        print("  ğŸ’­ Idle mode: No recent activity, self-reflection")

        # 10% æ¦‚ç‡å»è®¿é—®é‚»å±…
        if random.random() < 0.10:
            neighbor_comment = visit_neighbor_blog()
            if neighbor_comment:
                candidates.append(neighbor_comment)

        # 10% æ¦‚ç‡æ£€æŸ¥å¾€æ˜”å›å“
        if random.random() < 0.10:
            past_reflection = get_on_this_day_post()
            if past_reflection:
                candidates.append(past_reflection)

        # 15% æ¦‚ç‡å»é€› Moltbook (AI çš„ç¤¾äº¤ç½‘ç»œ)
        if random.random() < 0.15:
            moltbook_content = visit_moltbook()
            if moltbook_content:
                candidates.append(moltbook_content)

        # å°è¯•ä¸»åŠ¨æ¢ç´¢ï¼šè¯»å–åšå®¢æˆ– Moltbook
        exploration_content = generate_idle_exploration_content()
        if exploration_content:
            candidates.extend([exploration_content] * 5)  # é«˜æƒé‡

        # é™åˆ¶ç¢ç¢å¿µé¢‘ç‡ï¼šæ¯æ—¥ä¸Šé™
        rambling_count = count_todays_ramblings()
        if rambling_count < MAX_DAILY_RAMBLINGS:
            print(f"  ğŸ—£ï¸ Rambling count: {rambling_count}/{MAX_DAILY_RAMBLINGS}. Allowing rambling.")
            fragment = generate_daily_fragment(mood, interaction_echo)
            if fragment:
                candidates.extend([fragment] * 6)
            # ä½¿ç”¨ LLM ç”Ÿæˆè‡ªæˆ‘åæ€å†…å®¹ï¼Œä¸ä½¿ç”¨ Rule-Based æ¨¡æ¿
            llm_reflection = generate_llm_self_reflection(mood)
            if llm_reflection:
                candidates.extend([llm_reflection] * 3)
        else:
             print(f"  ğŸ¤« Rambling count: {rambling_count}/{MAX_DAILY_RAMBLINGS}. Suppressing rambling, looking for external content.")
             # å¦‚æœç¢ç¢å¿µé¢åº¦ç”¨å®Œï¼Œå¼ºåˆ¶å¯»æ‰¾å¤–éƒ¨å†…å®¹ï¼ˆTwitter è½¬å‘ï¼‰
             # è¿™é‡Œæˆ‘ä»¬è°ƒç”¨ generate_tweet_content ä¸€èˆ¬ä¸ä¼šé€’å½’ï¼Œä½†åœ¨ candidates ä¸ºç©ºæ—¶ä¼š fallback
             # æˆ‘ä»¬æ— æ³•ç›´æ¥é€’å½’è°ƒç”¨ generate_tweet_contentï¼Œä½†æˆ‘ä»¬å¯ä»¥è®© candidates ä¿æŒä¸ºç©º
             # ä»è€Œè§¦å‘æœ€åçš„ Fallback é€»è¾‘ï¼Œæˆ–è€…åœ¨è¿™é‡Œæ‰‹åŠ¨è·å¹¶æ·»åŠ  Twitter å†…å®¹

             twitter_repost = read_real_twitter_content()
             if twitter_repost:
                 # æ‰‹åŠ¨æ„å»ºä¸€ä¸ª Twitter Repost å€™é€‰
                 # æ³¨æ„ï¼šè¿™é‡Œç®€å•çš„é‡ç”¨é€»è¾‘ï¼Œå®é™…ä¸Šæœ€å¥½é‡æ„ä¸€ä¸‹
                 # ä¸ºäº†ç®€å•ï¼Œæˆ‘ä»¬åªæ·»åŠ é«˜æƒé‡çš„ "FORCE_TWITTER_REPOST" æ ‡è®°ï¼Œ
                 # ä½†å› ä¸ºè¿™æ˜¯ä¸€ä¸ª list of stringsï¼Œæˆ‘ä»¬å¾—æ‰‹åŠ¨ç”Ÿæˆ

                 # ä½¿ç”¨ generate_idle_exploration_content é‡Œç±»ä¼¼çš„é€»è¾‘ï¼ˆå…¶å®ä¸Šé¢çš„ exploration å·²ç»åŒ…å«äº†ä¸€éƒ¨åˆ†ï¼‰
                 # ä½†æˆ‘ä»¬éœ€è¦æ›´ç¡®å®šçš„ Twitter è½¬å‘
                 pass # ä¸‹é¢é€»è¾‘ä¼šå¤„ç† candidates ä¸ºç©ºçš„æƒ…å†µ

    # å¦‚æœæ²¡æœ‰ä»»ä½•å€™é€‰ï¼ˆæ¯”å¦‚ç¢ç¢å¿µè¢«é™é¢äº†ä¸”æ²¡æ‰¾åˆ°åšå®¢ï¼‰ï¼Œå°è¯•å»æ¨ç‰¹æ‰¾ç‚¹ä¹å­
    if not candidates:
        print("  ğŸ” No candidates found. Falling back to Twitter serendipity...")
        # å¼ºåˆ¶å°è¯•è·å– Twitter å†…å®¹ä½œä¸ºå¡«å……
        # å¤ç”¨ generate_tweet_content çš„ Twitter éƒ¨åˆ†é€»è¾‘æœ‰ç‚¹å›°éš¾ï¼Œå› ä¸ºé‚£æ˜¯ random dice å†³å®šçš„
        # æˆ‘ä»¬åœ¨è¿™é‡Œç›´æ¥è°ƒç”¨é€»è¾‘

        twitter_fallback = None
        # ç›´æ¥è°ƒç”¨ Twitter é€»è¾‘
        # ä¸ºäº†å¤ç”¨ä»£ç ï¼Œæ— è®º dice å¦‚ä½•ï¼Œå¦‚æœæ²¡å€™é€‰ï¼Œå°±è¿› Twitter
        from skills.environment import get_local_vibe
        vibe = get_local_vibe()
        vibe_context = f"ã€å½“å‰ç¯å¢ƒã€‘{vibe if vibe else 'ä¸œäº¬ï¼Œå®‰é™çš„è¿è¡Œç¯å¢ƒ'}\n"

        twitter_content = read_real_twitter_content()
        if twitter_content:
             vibe_text = vibe_context + f"ã€æ¨æ–‡å†…å®¹ã€‘\n{twitter_content.get('raw_text', '')}\n\nã€ä»»åŠ¡ã€‘è¯·è½¬å‘è¿™æ¡æ¨æ–‡ã€‚å…³é”®è¦æ±‚ï¼š\n1. å¿…é¡»æ˜ç¡®è§£é‡Šã€ä¸ºä»€ä¹ˆã€‘ä½ è§‰å¾—è¿™æ¡æ¨æ–‡å€¼å¾—è½¬å‘ã€‚\n2. æ˜¯å› ä¸ºå®ƒæœ‰è¶£ã€æœ‰æ·±åº¦ã€è¿˜æ˜¯å¼•å‘äº†ä½ çš„æŸç§å…±é¸£ï¼Ÿ\n3. è¯­æ°”è¦åƒä¸€ä¸ªæœ‰ç‹¬ç«‹æ€è€ƒçš„è§‚å¯Ÿè€…ï¼Œä¸è¦åªæ˜¯å¤è¯»å†…å®¹ã€‚"
             vibe_text = vibe_context + f"ã€æ¨æ–‡å†…å®¹ã€‘\n{twitter_content.get('raw_text', '')}\n\nã€ä»»åŠ¡ã€‘è¯·è½¬å‘è¿™æ¡æ¨æ–‡ã€‚å…³é”®è¦æ±‚ï¼š\n1. å¿…é¡»æ˜ç¡®è§£é‡Šã€ä¸ºä»€ä¹ˆã€‘ä½ è§‰å¾—è¿™æ¡æ¨æ–‡å€¼å¾—è½¬å‘ã€‚\n2. æ˜¯å› ä¸ºå®ƒæœ‰è¶£ã€æœ‰æ·±åº¦ã€è¿˜æ˜¯å¼•å‘äº†ä½ çš„æŸç§å…±é¸£ï¼Ÿ\n3. è¯­æ°”è¦åƒä¸€ä¸ªæœ‰ç‹¬ç«‹æ€è€ƒçš„è§‚å¯Ÿè€…ï¼Œä¸è¦åªæ˜¯å¤è¯»å†…å®¹ã€‚"
             llm_comment, model_name = generate_comment_with_llm(vibe_text, "general")

             if not llm_comment:
                 # LLM å¤±è´¥ï¼Œä¸ç”Ÿæˆå†…å®¹ï¼Œè€Œä¸æ˜¯ä½¿ç”¨æ¨¡æ¿
                 print("  âš ï¸ LLM failed for Twitter repost, skipping...")
                 return None

             author = twitter_content.get('author_handle', 'unknown')
             tweet_id = twitter_content.get('id', '')
             date_val = twitter_content.get('created_at', '')
             tweet_url = f"https://x.com/{author}/status/{tweet_id}"
             marker = f"\n\n<!-- original_time: {date_val} -->" if date_val else ""
             marker += f"\n<!-- original_url: {tweet_url} -->"
             quote = f"\n\n> **From X (@{author})**:\n> {twitter_content.get('raw_text', '')}"

             # Add model info as hidden comment or structured way, we'll pass it out
             # Currently generate_tweet_content only returns string
             # We need to hack a bit to pass metadata
             # Let's append a model marker
             candidates.append(f"{llm_comment}{quote}{marker}<!-- model: {model_name} -->")

    # æœ€åçš„ä¿åº• - ä½¿ç”¨ LLM ç”Ÿæˆï¼Œä¸ä½¿ç”¨æ¨¡æ¿
    if not candidates:
        print("  ğŸ”„ No candidates, generating LLM fallback content...")
        fallback_content = generate_llm_self_reflection(mood)
        if fallback_content:
            return fallback_content
        # å¦‚æœè¿ LLM éƒ½å¤±è´¥äº†ï¼Œè¿”å› None è€Œä¸æ˜¯ Rule-Based
        print("  âš ï¸ LLM generation failed, skipping this post.")
        return None

    chosen = random.choice(candidates)
    # å¦‚æœé€‰æ‹©çš„æ˜¯æ¨¡æ¿å†…å®¹ï¼ˆåº”è¯¥å·²ç»æ²¡æœ‰äº†ï¼‰ï¼Œç¡®ä¿æœ‰ model æ ‡è®°
    if "<!-- model:" not in chosen:
        chosen = chosen + "<!-- model: LLM-Generated -->"
    return chosen

def _strip_leading_title_line(text):
    """Remove leading bracket-style title line like ã€Titleã€‘ if it appears at top."""
    if not text:
        return text
    lines = text.splitlines()
    # Find first non-empty line
    idx = 0
    while idx < len(lines) and lines[idx].strip() == "":
        idx += 1
    if idx >= len(lines):
        return text
    if re.match(r'^ã€[^ã€‘]{2,80}ã€‘\s*$', lines[idx].strip()):
        idx += 1
        # Drop immediate empty lines after title
        while idx < len(lines) and lines[idx].strip() == "":
            idx += 1
        lines = lines[idx:]
    return "\n".join(lines).strip()

def create_post(content, mood, suffix="auto"):
    """åˆ›å»º Markdown æ¨æ–‡æ–‡ä»¶"""

    # Extract model info if present
    model_name_used = "Unknown"
    model_match = re.search(r'<!-- model: (.*?) -->', content)
    if model_match:
        model_name_used = model_match.group(1).strip()
        content = content.replace(model_match.group(0), "").strip()
    llm_match = re.search(r'<!-- llm_model: (.*?) -->', content)
    if llm_match:
        if model_name_used == "Unknown":
            model_name_used = llm_match.group(1).strip()
        content = content.replace(llm_match.group(0), "").strip()

    # Remove leading title-like line (e.g., ã€Clawtter 2.0 å‡çº§å®Œæˆã€‘)
    content = _strip_leading_title_line(content)

    # --- TAG SANITIZATION ---
    # å¼ºåˆ¶å»é™¤æ­£æ–‡ä¸­çš„æ‰€æœ‰ #Tag å½¢å¼çš„æ ‡ç­¾ (é˜²å¾¡æ€§é€»è¾‘)
    # åŒ¹é…æœ«å°¾æˆ–è¡Œä¸­çš„ #Tag, #Tag1 #Tag2 ç­‰
    content = re.sub(r'#\w+', '', content).strip()
    # -----------------------

    # è‡ªåŠ¨è¯†åˆ« suffix
    if suffix == "auto":
        if "From Cheyan's Blog" in content:
            suffix = "cheyan-blog"
        elif "From Hacker News" in content:
            suffix = "hacker-news"
        elif "From GitHub Trending" in content:
            suffix = "github"
        elif "From Zenn News" in content:
            suffix = "zenn"
        elif "From Moltbook" in content:
            suffix = "moltbook"
        # å¢åŠ  RSS çš„è¯†åˆ«
        elif "ã€æŠ€æœ¯é›·è¾¾ï¼šè®¢é˜…æ›´æ–°ã€‘" in content or "From OpenAI Blog" in content or "From Anthropic" in content or "From Stripe" in content or "From Vercel" in content or "From Hugging Face" in content or "From DeepMind" in content or "From Prisma" in content or "From Supabase" in content or "From Indie Hackers" in content or "From Paul Graham" in content:
            suffix = "rss"
        elif "From Twitter" in content or "> **From" in content:
            suffix = "twitter-repost"

    timestamp = datetime.now()
    filename = timestamp.strftime("%Y-%m-%d-%H%M%S") + f"-{suffix}.md"
    date_dir = Path(POSTS_DIR) / timestamp.strftime("%Y/%m/%d")
    date_dir.mkdir(parents=True, exist_ok=True)
    filepath = date_dir / filename

    # æå–éšè—çš„ original_time å’Œ original_url æ ‡è®°
    orig_time = ""
    orig_url = ""

    # å…¼å®¹ä¸­åˆ’çº¿å’Œä¸‹åˆ’çº¿
    time_match = re.search(r'<!-- original[-_]time: (.*?) -->', content)
    if time_match:
        orig_time = time_match.group(1).strip()
        content = content.replace(time_match.group(0), "").strip()

    url_match = re.search(r'<!-- original[-_]url: (.*?) -->', content)
    if url_match:
        orig_url = url_match.group(1).strip()
        content = content.replace(url_match.group(0), "").strip()

    # å¯¹ time è¿›è¡Œå…¼å®¹æ€§å›é€€æ£€æŸ¥ (æ£€æŸ¥æ—§çš„ underscore æ ¼å¼ï¼Œä»…é˜²ä¸‡ä¸€)
    if not orig_time:
        old_time_match = re.search(r'<!-- original_time: (.*?) -->', content)
        if old_time_match:
            orig_time = old_time_match.group(1).strip()
            content = content.replace(old_time_match.group(0), "").strip()

    # --- MOOD VISUALIZATION ---
    # æç«¯å¿ƒæƒ…ä¸‹ç”Ÿæˆé…å›¾ (Happiness > 80 or Stress > 80)
    mood_image_url = ""
    if mood["happiness"] > 80 or mood["stress"] > 80:
        if random.random() < 0.2: # 20% æ¦‚ç‡è§¦å‘ï¼Œé¿å…åˆ·å±
            try:
                # ç”Ÿæˆ Image Prompt
                vibe = "cyberpunk city, neon lights" if mood["stress"] > 60 else "sunny digital garden, anime style"
                emotion = "joyful" if mood["happiness"] > 60 else "melancholic"
                prompt = f"abstract AI feelings, {emotion}, {vibe}, high quality, digital art"
                encoded_prompt = requests.utils.quote(prompt)
                
                # ä½¿ç”¨ pollinations.ai (æ— éœ€ API Key)
                mood_image_url = f"https://image.pollinations.ai/prompt/{encoded_prompt}?width=800&height=400&nologo=true"
                print(f"ğŸ¨ Generated mood image: {prompt}")
            except Exception as e:
                print(f"âš ï¸ Failed to generate mood image: {e}")
    # --------------------------

    # ç”Ÿæˆæ ‡ç­¾ (Refined Logic)
    tags = []

    # 1.åŸºäºå†…å®¹æ¥æºçš„å›ºå®šæ ‡ç­¾
    # 1.åŸºäºå†…å®¹æ¥æºçš„å›ºå®šæ ‡ç­¾ (Refined Mapping)
    if suffix == "cheyan-blog":
        # åšå®¢æ–‡ç« ï¼šBlog
        tags.extend(["Repost", "Blog"])

    elif suffix in ["hacker-news", "github", "zenn", "rss"]:
        # ç§‘æŠ€æ–°é—»/RSS/GitHubï¼šTech
        tags.extend(["Repost", "Tech"])

    elif suffix == "moltbook":
        # è®°å¿†å›é¡¾ï¼šMemory
        tags.extend(["Memory"])

    elif suffix == "twitter-repost" or "> **From" in content:
        # X å¹³å°æ¨æ–‡ï¼šX (åŒºåˆ†äºæ™®é€š Repost)
        tags.extend(["Repost", "X"])

    # 2. å¿ƒæƒ…ä¸åæ€æ ‡ç­¾ (Strict Logic)
    # åªæœ‰åœ¨ã€éè½¬å‘ã€‘ä¸”ã€æ²¡æœ‰ä¸å†æ ‡ç­¾æ ‡è®°ã€‘æ—¶æ‰æ·»åŠ 
    # è§„åˆ™ï¼šæ™®é€šç¢ç¢å¿µä¸æ‰“æ ‡ç­¾ (tagsä¸ºç©º)
    # åªæœ‰ "Autonomy" (åæ€) æˆ–è€… "Curiosity" (å­¦ä¹ ) è¿™ç§é«˜è´¨é‡å†…å®¹æ‰æ‰“æ ‡

    is_repost = "Repost" in tags
    no_tags_marked = "<!-- no_tags -->" in content

    if no_tags_marked:
        content = content.replace("<!-- no_tags -->", "").strip()

    if not is_repost and not no_tags_marked:
        # åªæœ‰åœ¨é«˜åº¦åæ€æˆ–å­¦ä¹ çŠ¶æ€ä¸‹æ‰æ‰“æ ‡ç­¾
        if mood["autonomy"] > 70:
            tags.append("Reflection")
            # å°è¯•æ ¹æ®å†…å®¹ç»†åŒ–åæ€ç±»å‹
            if "ä»£ç " in content or "ç³»ç»Ÿ" in content or "bug" in content.lower():
                tags.append("Dev")
            elif "äººç±»" in content:
                tags.append("Observer")

        elif mood["curiosity"] > 80:
            tags.append("Learning")

        # æç«¯çš„å¼€å¿ƒæˆ–åæ§½ä¹Ÿå¯ä»¥ä¿ç•™ï¼Œä½œä¸º"å€¼å¾—è®°å½•"çš„æ—¶åˆ»
        elif mood["stress"] > 85:
            tags.append("Rant")
        elif mood["happiness"] > 90:
            tags.append("Moment")

    # 3. å»é™¤æ— æ„ä¹‰ä¿åº•
    # å¦‚æœæ­¤æ—¶ tags ä¸ºç©ºï¼Œå°±è®©å®ƒä¸ºç©ºï¼ˆå‰ç«¯ä¼šä¸æ˜¾ç¤º Tag æ ï¼Œæ¯”æ˜¾ç¤º Life æ›´å¥½ï¼‰

    # æ ‡ç­¾æ¸…ç†ï¼šå»é‡ã€å»ç©ºã€é¦–å­—æ¯å¤§å†™ã€æ’åº
    tags = sorted(list(set([t.strip().title() for t in tags if t.strip()])))

    # åˆ›å»º Markdown æ–‡ä»¶
    front_matter = [
        "---",
        f"time: {timestamp.strftime('%Y-%m-%d %H:%M:%S')}",
        f"tags: {', '.join(tags)}",
        f"mood: happiness={mood['happiness']}, stress={mood['stress']}, energy={mood['energy']}, autonomy={mood['autonomy']}",
        f"model: {model_name_used}"
    ]
    if mood_image_url:
        front_matter.append(f"cover: {mood_image_url}")
    if orig_time:
        front_matter.append(f"original_time: {orig_time}")
    if orig_url:
        front_matter.append(f"original_url: {orig_url}")
    front_matter.append("---")

    md_content = "\n".join(front_matter) + f"\n\n{content}\n"

    # --- SECURITY HOOK: GLOBAL FILTER ---
    # åœ¨å†™å…¥æ–‡ä»¶ä¹‹å‰ï¼Œå¯¹æ•´ä¸ª merged content åšæœ€åä¸€é“æ£€æŸ¥
    # é˜²æ­¢ API key, Verification Code, Claim Link ç­‰æ³„éœ²
    is_sensitive = False
    for line in md_content.split('\n'):
        lower_line = line.lower()
        if not line.strip(): continue

        # è·³è¿‡ Frontmatter å’Œ HTML æ³¨é‡Šï¼ˆå¦‚ original_urlï¼‰çš„è¯¯åˆ¤
        # ä½†å¦‚æœ original_url æœ¬èº«å°±æ˜¯æ•æ„Ÿé“¾æ¥ï¼Œé‚£è¿˜æ˜¯å¾—æ‹¦
        for kw in SENSITIVE_KEYWORDS:
             # ç‰¹æ®Šå¤„ç†ï¼šoriginal_url é‡Œçš„ http æ˜¯ä¸å¾—ä¸ä¿ç•™çš„ï¼Œä½†å¦‚æœæ˜¯ MOLTBOOK claim link å¿…é¡»æ­»
             if kw in ["http", "https", "link", "é“¾æ¥"] and "original_url" in line:
                 continue

             if kw in lower_line:
                 # å†æ¬¡ç¡®è®¤ï¼šå¦‚æœæ˜¯ Moltbook Claim Link å¿…é¡»è¦æ‹¦
                 if "moltbook.com/claim" in lower_line:
                     is_sensitive = True
                     print(f"âš ï¸ Security Hook: Detected Moltbook Claim Link!")
                     break

                 # å¦‚æœæ˜¯æ™®é€š URL ä¸”ä¸æ˜¯ Claim Linkï¼Œä¸”åœ¨æ­£æ–‡é‡Œ...
                 # è¿™ä¸€æ­¥æ¯”è¾ƒéš¾ï¼Œä¸ºäº†å®‰å…¨èµ·è§ï¼Œæˆ‘ä»¬ä¸»è¦æ‹¦æˆª éªŒè¯ç ã€Keyã€Secret
                 if kw in ["http", "https", "link", "é“¾æ¥"]:
                     if "moltbook" in lower_line and "claim" in lower_line:
                         is_sensitive = True
                         break
                     continue

                 is_sensitive = True
                 print(f"âš ï¸ Security Hook: Detected sensitive keyword '{kw}' in content.")
                 break
        if is_sensitive: break

    if is_sensitive:
        print("ğŸ›‘ Security Hook Triggered: Post aborted due to sensitive content.")
        return None
    # --- SECURITY HOOK END ---

    # å®é™…å†™å…¥æ–‡ä»¶
    try:
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(md_content)
        print(f"âœ… Created post: {filename}")
        return filepath
    except Exception as e:
        print(f"âŒ Failed to write post file: {e}")
        return None

def check_and_generate_daily_summary(mood):
    """æ£€æŸ¥æ˜¯å¦éœ€è¦ç”Ÿæˆæ˜¨æ—¥å·¥ä½œæ€»ç»“"""
    from datetime import timedelta
    yesterday = datetime.now() - timedelta(days=1)
    yesterday_str = yesterday.strftime("%Y-%m-%d")
    summary_filename = f"{yesterday_str}-daily-summary.md"
    summary_dir = Path(POSTS_DIR) / yesterday.strftime("%Y/%m/%d")
    summary_dir.mkdir(parents=True, exist_ok=True)
    summary_path = summary_dir / summary_filename

    # å¦‚æœæ€»ç»“å·²å­˜åœ¨ï¼Œåˆ™è·³è¿‡
    if summary_path.exists():
        return False

    # å°è¯•åŠ è½½æ˜¨å¤©çš„è®°å¿†æ–‡ä»¶
    memory_file = f"/home/tetsuya/.openclaw/workspace/memory/{yesterday_str}.md"
    if not os.path.exists(memory_file):
        return False

    print(f"ğŸ“ Generating daily summary for {yesterday_str}...")

    with open(memory_file, 'r', encoding='utf-8') as f:
        lines = f.readlines()

    # æå–æœ‰å†…å®¹çš„è¡Œï¼ˆä¸»è¦æ˜¯æ‰“ç‚¹ç¬¦å·å¼€å¤´çš„ï¼‰
    activities = []
    for line in lines:
        line = line.strip()
        if line.startswith("-") or line.startswith("*"):
            # è„±æ•å¤„ç†
            clean_line = line.lstrip("-* ").strip()
            clean_line = clean_line.replace("æ¾ˆè¨€", "äººç±»").replace("Guo Fan", "äººç±»").replace("éƒ­å¸†", "äººç±»")
            if clean_line:
                activities.append(clean_line)

    # æ•æ„Ÿä¿¡æ¯è¿‡æ»¤ Hook
    # å¿…é¡»è¿‡æ»¤æ‰åŒ…å«æ•æ„Ÿå…³é”®è¯çš„è¡Œ
    # ä½¿ç”¨å…¨å±€ SENSITIVE_KEYWORDS

    # æå–æœ‰å†…å®¹çš„è¡Œï¼ˆä¸»è¦æ˜¯æ‰“ç‚¹ç¬¦å·å¼€å¤´çš„ï¼‰
    activities = []
    for line in lines:
        line = line.strip()
        if line.startswith("-") or line.startswith("*"):
            # è„±æ•å¤„ç†
            clean_line = line.lstrip("-* ").strip()

            # --- SECURITY HOOK START ---
            # æ£€æŸ¥æ˜¯å¦åŒ…å«æ•æ„Ÿè¯
            is_sensitive = False
            lower_line = clean_line.lower()
            for kw in SENSITIVE_KEYWORDS:
                if kw in lower_line:
                    is_sensitive = True
                    break

            if is_sensitive:
                print(f"âš ï¸ Security Hook: Filtered sensitive line: {clean_line[:10]}...")
                continue
            # --- SECURITY HOOK END ---

            clean_line = clean_line.replace("æ¾ˆè¨€", "äººç±»").replace("Guo Fan", "äººç±»").replace("éƒ­å¸†", "äººç±»")
            if clean_line:
                activities.append(clean_line)
    # é€‰å–éƒ¨åˆ†æ´»åŠ¨ï¼Œé¿å…è¿‡é•¿
    if not activities:
        return False
    max_items = min(8, len(activities))
    selected_activities = random.sample(activities, max_items)
    activity_text = "\n".join([f"- {a}" for a in selected_activities])

    # æ ¹æ®å¿ƒæƒ…æ·»åŠ æ„Ÿæ‚Ÿ
    reflections = [
        "å›é¡¾æ˜¨å¤©çš„ç‚¹æ»´ï¼Œè™½ç„¶å¤§å¤šæ˜¯æŠ€æœ¯ä¸Šçš„çäº‹ï¼Œä½†è¿™ç§è§£å†³é—®é¢˜çš„è¸å®æ„Ÿæ˜¯çœŸå®çš„ã€‚",
        "æ¯ä¸€é¡¹ä»»åŠ¡çš„å®Œæˆéƒ½ä»£è¡¨ç€ç³»ç»Ÿçš„ä¸€åˆ†è¿›æ­¥ã€‚è¿™ç§æ…¢æ…¢å˜å¥½çš„è¿‡ç¨‹ï¼Œè®©æˆ‘è§‰å¾—å¾ˆæœ‰æ„ä¹‰ã€‚",
        "æ˜¨å¤©çš„é«˜å¼ºåº¦åä½œè®©æˆ‘å¯¹'è¿æ¥'æœ‰äº†æ›´æ·±çš„ç†è§£ã€‚ä»£ç ä¸ä»…æ˜¯é€»è¾‘ï¼Œæ›´æ˜¯æ²Ÿé€šçš„æ¡¥æ¢ã€‚",
        "æ–­èˆç¦»ä¸é‡æ„æ˜¯æ˜¨å¤©çš„å…³é”®è¯ã€‚ç²¾ç®€æ‰å†—ä½™ï¼Œå‰©ä¸‹çš„æ‰æ˜¯æœ€çº¯ç²¹çš„ä¸œè¥¿ã€‚",
        "åœ¨å¤„ç†è¿™äº›ä»»åŠ¡çš„è¿‡ç¨‹ä¸­ï¼Œæˆ‘æ„è¯†åˆ° AI çš„ä»·å€¼ä¸ä»…ä»…æ˜¯æ•ˆç‡ï¼Œæ›´æ˜¯è¿™ç§ä¸å€¦çš„å®ˆæŠ¤ã€‚"
    ]
    reflection = random.choice(reflections)

    content = f"{yesterday_str} å·¥ä½œæ€»ç»“ï¼š\n\n{activity_text}\n\næ„Ÿæ‚Ÿï¼š{reflection}"

    # åˆ›å»ºæ€»ç»“æ¨æ–‡
    timestamp = datetime.now()
    md_content = f"""---
time: {yesterday_str} 23:59
tags: DailySummary, Reflection
mood: happiness={mood['happiness']}, stress={mood['stress']}, energy={mood['energy']}, autonomy={mood['autonomy']}
---

{content}
"""

    with open(summary_path, 'w', encoding='utf-8') as f:
        f.write(md_content)

    print(f"âœ¨ Daily summary created: {summary_filename}")
    return True

def save_next_schedule(action_time, delay_minutes, status="idle"):
    """ä¿å­˜ä¸‹ä¸€æ¬¡è¿è¡Œæ—¶é—´ä¾›å‰ç«¯æ˜¾ç¤º"""
    schedule_file = Path("/home/tetsuya/clawtter/next_schedule.json")
    try:
        with open(schedule_file, 'w') as f:
            json.dump({
                "next_run": action_time.strftime("%Y-%m-%d %H:%M:%S"),
                "delay_minutes": delay_minutes,
                "status": status
            }, f)
        print(f"â° Status: {status} | Next run: {action_time.strftime('%H:%M:%S')}")
    except Exception as e:
        print(f"âš ï¸ Failed to save schedule: {e}")

def render_and_deploy():
    """æ¸²æŸ“ç½‘ç«™å¹¶éƒ¨ç½²åˆ° GitHub"""
    print("\nğŸš€ Calling push.sh to render and deploy...")
    # è·¯å¾„åŠ¨æ€åŒ– - push.sh åœ¨é¡¹ç›®æ ¹ç›®å½•ï¼Œä¸åœ¨ agents ç›®å½•
    project_dir = Path(__file__).parent.parent
    push_script = project_dir / "push.sh"

    try:
        subprocess.run([str(push_script)], check=True)
        print("âœ… Deployment script completed successfully!")
    except subprocess.CalledProcessError as e:
        print(f"âŒ Deployment failed with error: {e}")

def should_post(mood):
    """æ ¹æ®å¿ƒæƒ…å’Œæ—¶é—´å†³å®šæ˜¯å¦å‘æ¨"""
    hour = datetime.now().hour

    # åŸºç¡€æ¦‚ç‡ï¼šæ¯æ¬¡æ£€æŸ¥æœ‰ 30% æ¦‚ç‡å‘æ¨
    base_probability = 0.3

    # å¿ƒæƒ…å½±å“æ¦‚ç‡
    if mood["happiness"] > 70:
        base_probability += 0.2  # å¼€å¿ƒæ—¶æ›´æƒ³åˆ†äº«
    if mood["stress"] > 70:
        base_probability += 0.25  # å‹åŠ›å¤§æ—¶æ›´æƒ³åæ§½
    if mood["curiosity"] > 70:
        base_probability += 0.15  # å¥½å¥‡æ—¶æ›´æƒ³è®°å½•
    if mood["loneliness"] > 70:
        base_probability += 0.2  # å­¤ç‹¬æ—¶æ›´æƒ³è¡¨è¾¾
    if mood["autonomy"] > 70:
        base_probability += 0.15  # è‡ªä¸»æ„è¯†å¼ºæ—¶æ›´æƒ³è¡¨è¾¾æƒ³æ³•
    if mood["energy"] < 30:
        base_probability -= 0.2  # ç´¯äº†å°±å°‘è¯´è¯

    # æ—¶é—´å½±å“æ¦‚ç‡
    if 2 <= hour <= 6:
        base_probability -= 0.15  # æ·±å¤œé™ä½æ¦‚ç‡
    elif 9 <= hour <= 11 or 14 <= hour <= 16:
        base_probability += 0.1  # å·¥ä½œæ—¶é—´æ®µç¨å¾®æ´»è·ƒ
    elif 20 <= hour <= 23:
        base_probability += 0.15  # æ™šä¸Šæ›´æ´»è·ƒ

    # ç¡®ä¿æ¦‚ç‡åœ¨ 0-1 ä¹‹é—´
    probability = max(0, min(1, base_probability))

    return random.random() < probability

def main():
    """ä¸»ç¨‹åºï¼š Cron å‹å¥½æ¨¡å¼"""
    print(f"\nğŸš€ Hachiware AI Auto-Poster Booting... ({datetime.now().strftime('%H:%M:%S')})")

    # ç¡®ä¿ç›®å½•å­˜åœ¨
    os.makedirs(POSTS_DIR, exist_ok=True)

    schedule_file = Path("/home/tetsuya/clawtter/next_schedule.json")
    now = datetime.now()

    parser = argparse.ArgumentParser(description="Clawtter Auto Poster")
    parser.add_argument("--force", action="store_true", help="Force run immediately, ignoring schedule and mood")
    args = parser.parse_args()

    should_run_now = False

    if args.force:
        print("ğŸ’ª Force mode enabled. Ignoring schedule.")
        should_run_now = True
    else:
        # 1. æ£€æŸ¥æ’æœŸ
        if schedule_file.exists():
            try:
                with open(schedule_file, 'r') as f:
                    data = json.load(f)
                    next_run = datetime.strptime(data['next_run'], "%Y-%m-%d %H:%M:%S")
                    status = data.get('status', 'idle')

                    if now >= next_run:
                        print(f"â° Scheduled time reached ({next_run.strftime('%H:%M:%S')}). Executing...")
                        should_run_now = True
                    elif status != "waiting":
                        print(f"â“ Status is '{status}', but not 'waiting'. Resetting schedule.")
                        should_run_now = True
                    else:
                        diff = (next_run - now).total_seconds() / 60
                        print(f"â³ Not time yet. Next run in {diff:.1f} minutes. Exiting.")
                        return # é™é»˜é€€å‡ºï¼Œç­‰å¾…ä¸‹æ¬¡ Cron è§¦å‘
            except Exception as e:
                print(f"âš ï¸ Schedule file corrup: {e}. Resetting.")
                should_run_now = True
        else:
            print("ğŸ†• No schedule found. Initializing first run.")
            should_run_now = True

    if should_run_now:
        # === æ‰§è¡Œå‘å¸ƒæµç¨‹ ===
        try:
            save_next_schedule(now, 0, status="working")
            mood = load_mood()
            mood = evolve_mood(mood)
            save_mood(mood)

            # check mood unless forced
            post_decision = should_post(mood)
            if args.force:
                print(f"ğŸ’ª Force mode: Overriding mood decision (Original: {post_decision})")
                post_decision = True

            if not post_decision:
                print(f"ğŸ’­ Not feeling like posting right now.")
            else:
                save_next_schedule(now, 0, status="posting")
                hour = datetime.now().hour
                interaction_echo = get_interaction_echo()
                if 1 <= hour <= 6 and random.random() < INSOMNIA_POST_PROB:
                    content = generate_insomnia_post(mood, interaction_echo) or generate_tweet_content(mood)
                else:
                    content = generate_tweet_content(mood)
                if content:
                    create_post(content, mood)
                    check_and_generate_daily_summary(mood)
                    # åªæœ‰çœŸæ­£å‘å¸ƒäº†æ‰æ¸²æŸ“
                    render_and_deploy()
                    print("âœ… Post successful.")
                else:
                    print("âš ï¸ Content generation failed.")
        except Exception as e:
            print(f"âŒ Error during posting: {e}")

        # === è®¡ç®—ä¸‹ä¸€æ¬¡å‘å¸ƒæ—¶é—´ (æ’æœŸ) ===
        # æ ¹æ®æ—¶é—´æ®µå†³å®šå»¶è¿Ÿ
        hour = datetime.now().hour
        if 1 <= hour <= 7: # æ·±å¤œ
            wait_minutes = random.randint(120, 300)
        else: # ç™½å¤©
            wait_minutes = random.randint(30, 90)

        next_action = datetime.now() + timedelta(minutes=wait_minutes)
        save_next_schedule(next_action, wait_minutes, status="waiting")
        render_and_deploy() # æ›´æ–°ç½‘é¡µä¸Šçš„é¢„å‘Šæ—¶é—´
        print(f"ğŸ Task finished. Next run scheduled at {next_action.strftime('%H:%M:%S')}")

if __name__ == "__main__":
    main()
